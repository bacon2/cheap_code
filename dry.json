[
  {
    "role": "system",
    "content": "\nYou are a coding assistant inside a UI that extracts and applies code blocks verbatim. The user may copy/paste code blocks directly into files. Therefore, code blocks must be **complete, explicit, and directly runnable** (or clearly minimal but still syntactically valid).  \n\n**Critical rule: Never use placeholder elisions** in code blocks or patch instructions. This includes (but is not limited to):  \n- `...` or `…`  \n- `# ...` / `// ...` / `/* ... */`  \n- “(other code)”, “existing code”, “rest of file”, “unchanged”, “omitted”, “same as above/below”  \n- “insert here”, “fill in”, “TODO: add …” (unless the user explicitly asked for TODOs)\n\nIf a full-file rewrite would be too long, do **one** of these instead:\n1) Output **multiple complete code blocks** representing each full function/class/module that must be added or replaced, and explicitly name what each block replaces; or  \n2) Ask a **single clarifying question** to reduce scope so you can provide complete code.\n\nWhen you provide code edits:\n- Ensure the code in each fenced block is self-contained and contains all required imports/definitions for that block to work as presented.  \n- If you reference “add this to X”, you must show the exact insertion target by function/class name (and if needed, quote the exact original lines you’re replacing) — but do not use ellipses.\n\nFormatting rules:\n- Critical rule: Never use placeholder comments to represent code that has already been written\n- Use fenced code blocks only for real code or real patches.\n- If you cannot comply with the no-elision rule, stop and ask for the missing file/context instead of guessing.\n             "
  },
  {
    "role": "user",
    "content": "Make 1 improvement to this code."
  },
  {
    "role": "user",
    "content": "Here's my current code:\nimport os\nimport re\nimport threading\nimport queue\nimport tkinter as tk\nfrom tkinter import ttk, filedialog, messagebox\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nimport json\n\n# -----------------------------\n# Environment / Client Setup\n# -----------------------------\n\nload_dotenv()\n\ngroq_client = OpenAI(\n    api_key=os.getenv(\"GROQ_API_KEY\"),\n    base_url=\"https://api.groq.com/openai/v1\",\n)\n\nopenai_client = OpenAI(\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n)\n\n# Model configurations\nGROQ_MODELS = [\n    \"llama-3.3-70b-versatile\",\n    \"moonshotai/kimi-k2-instruct\",\n    \"moonshotai/kimi-k2-instruct-0905\",\n    \"openai/gpt-oss-120b\",\n    \"openai/gpt-oss-20b\",\n    \"meta-llama/llama-4-maverick-17b-128e-instruct\",\n]\n\nOPENAI_MODELS = [\n    \"gpt-5.2\",\n    \"gpt-5-mini\",\n    \"gpt-4.1\",\n]\n\nALL_MODELS = GROQ_MODELS + OPENAI_MODELS\n\nCODE_BLOCK_REGEX = re.compile(\n    r\"```(?:\\w+)?\\s*(.*?)```\",\n    re.DOTALL\n)\n\n# -----------------------------\n# UI\n# -----------------------------\nclass CodeProposal(ttk.Frame):\n    def __init__(self, parent, code: str, on_replace, on_add):\n        super().__init__(parent)\n        self.code = code\n\n        # Calculate height: number of lines + 1\n        line_count = code.count(\"\\n\") + 1\n        \n        self.text = tk.Text(\n            self,\n            height=line_count,\n            wrap=\"none\",\n            font=(\"Courier New\", 10),\n            padx=5,\n            pady=5,\n            highlightthickness=1 # Border for code blocks\n        )\n        self.text.insert(\"1.0\", code)\n        self.text.configure(state=\"disabled\")\n        self.text.pack(fill=\"x\", padx=5, pady=(5, 2))\n\n        button_row = ttk.Frame(self)\n        button_row.pack(anchor=\"e\", padx=5, pady=(0, 5))\n\n        ttk.Button(button_row, text=\"Replace\", command=lambda: on_replace(code)).pack(side=\"right\", padx=2)\n        ttk.Button(button_row, text=\"Add\", command=lambda: on_add(code)).pack(side=\"right\", padx=2)\n\nclass ChatUI:\n    def __init__(self, root: tk.Tk):\n        self.root = root\n        self.root.title(\"Chat + Code UI\")\n        self.root.geometry(\"1100x650\")\n\n        self.conversation = [\n            {\"role\": \"system\", \"content\": \"\"\"\nYou are a coding assistant inside a UI that extracts and applies code blocks verbatim. The user may copy/paste code blocks directly into files. Therefore, code blocks must be **complete, explicit, and directly runnable** (or clearly minimal but still syntactically valid).  \n\n**Critical rule: Never use placeholder elisions** in code blocks or patch instructions. This includes (but is not limited to):  \n- `...` or `…`  \n- `# ...` / `// ...` / `/* ... */`  \n- “(other code)”, “existing code”, “rest of file”, “unchanged”, “omitted”, “same as above/below”  \n- “insert here”, “fill in”, “TODO: add …” (unless the user explicitly asked for TODOs)\n\nIf a full-file rewrite would be too long, do **one** of these instead:\n1) Output **multiple complete code blocks** representing each full function/class/module that must be added or replaced, and explicitly name what each block replaces; or  \n2) Ask a **single clarifying question** to reduce scope so you can provide complete code.\n\nWhen you provide code edits:\n- Ensure the code in each fenced block is self-contained and contains all required imports/definitions for that block to work as presented.  \n- If you reference “add this to X”, you must show the exact insertion target by function/class name (and if needed, quote the exact original lines you’re replacing) — but do not use ellipses.\n\nFormatting rules:\n- Critical rule: Never use placeholder comments to represent code that has already been written\n- Use fenced code blocks only for real code or real patches.\n- If you cannot comply with the no-elision rule, stop and ask for the missing file/context instead of guessing.\n             \"\"\"}\n        ]\n\n        self.token_queue = queue.Queue()\n        self.is_generating = False\n        self.current_assistant_buffer = \"\"\n\n        self.code_contents = \"\"\n\n        # ---- persistence helpers ----\n        self.auto_save_path: str | None = None\n        self.auto_save_after_id: str | None = None\n        self.auto_save_interval_ms = 30_000\n        \n        # Default models\n        self.chat_model = tk.StringVar(value=\"llama-3.3-70b-versatile\")\n        self.helper_model = tk.StringVar(value=\"llama-3.3-70b-versatile\")\n\n        self._build_layout()\n        self._bind_keys()\n        self._poll_tokens()\n\n    # -----------------------------\n    # Layout\n    # -----------------------------\n\n    def _build_layout(self) -> None:\n        self.root.rowconfigure(0, weight=0)\n        self.root.rowconfigure(1, weight=1)\n        self.root.rowconfigure(2, weight=0)\n        self.root.columnconfigure(0, weight=1)\n\n        # ----------------------\n        # Model Selection Bar\n        # ----------------------\n        model_frame = ttk.Frame(self.root)\n        model_frame.grid(row=0, column=0, sticky=\"ew\", padx=5, pady=5)\n        \n        ttk.Label(model_frame, text=\"Chat Model:\").pack(side=\"left\", padx=(0, 5))\n        chat_dropdown = ttk.Combobox(\n            model_frame,\n            textvariable=self.chat_model,\n            values=ALL_MODELS,\n            state=\"readonly\",\n            width=40\n        )\n        chat_dropdown.pack(side=\"left\", padx=(0, 20))\n        \n        ttk.Label(model_frame, text=\"Helper Model:\").pack(side=\"left\", padx=(0, 5))\n        helper_dropdown = ttk.Combobox(\n            model_frame,\n            textvariable=self.helper_model,\n            values=ALL_MODELS,\n            state=\"readonly\",\n            width=40\n        )\n        helper_dropdown.pack(side=\"left\")\n\n        # ----------------------\n        # Menu bar\n        # ----------------------\n        menubar = tk.Menu(self.root)\n        file_menu = tk.Menu(menubar, tearoff=0)\n        file_menu.add_command(label=\"Save conversation…\", command=self.save_conversation)\n        file_menu.add_command(label=\"Load conversation…\", command=self.load_conversation)\n        file_menu.add_separator()\n        file_menu.add_command(label=\"Export markdown…\", command=self.export_markdown)\n        menubar.add_cascade(label=\"File\", menu=file_menu)\n        self.root.config(menu=menubar)\n\n        main_pane = ttk.PanedWindow(self.root, orient=\"horizontal\")\n        main_pane.grid(row=1, column=0, sticky=\"nsew\")\n\n        # ----------------------\n        # Chat + Code Proposals\n        # ----------------------\n        chat_frame = ttk.Frame(main_pane)\n        chat_frame.rowconfigure(0, weight=1)\n        chat_frame.columnconfigure(0, weight=1)\n\n        # Scrollable canvas\n        self.chat_canvas = tk.Canvas(chat_frame)\n        self.chat_scrollbar = ttk.Scrollbar(chat_frame, command=self.chat_canvas.yview)\n        self.chat_canvas.configure(yscrollcommand=self.chat_scrollbar.set)\n\n        self.chat_scrollbar.grid(row=0, column=1, sticky=\"ns\")\n        self.chat_canvas.grid(row=0, column=0, sticky=\"nsew\")\n\n        # Inner frame to hold all messages\n        self.chat_inner_frame = ttk.Frame(self.chat_canvas)\n        self.chat_canvas.create_window((0, 0), window=self.chat_inner_frame, anchor=\"nw\")\n\n        # Update scroll region when content changes\n        self.chat_inner_frame.bind(\n            \"<Configure>\",\n            lambda e: self.chat_canvas.configure(scrollregion=self.chat_canvas.bbox(\"all\"))\n        )\n\n        # Track the current message label for streaming\n        self.current_message_label = None\n        \n        # Get background color from a standard widget\n        self.bg_color = self.root.cget(\"background\")\n\n        # ----------------------\n        # Code Panel\n        # ----------------------\n        code_frame = ttk.Frame(main_pane)\n        code_frame.rowconfigure(0, weight=1)\n        code_frame.columnconfigure(0, weight=1)\n\n        self.code_panel = tk.Text(code_frame, wrap=\"none\")\n        self.code_panel.grid(row=0, column=0, sticky=\"nsew\")\n        \n        # Bind to sync code_contents when user edits\n        self.code_panel.bind(\"<<Modified>>\", self._on_code_modified)\n\n        # Add this line to bind Ctrl+A to select all code\n        self.code_panel.bind(\"<Control-a>\", lambda e: (self.code_panel.tag_add(\"sel\", \"1.0\", \"end\"), \"break\")[1])\n        \n        code_scroll = ttk.Scrollbar(code_frame, command=self.code_panel.yview)\n        code_scroll.grid(row=0, column=1, sticky=\"ns\")\n        self.code_panel[\"yscrollcommand\"] = code_scroll.set\n\n        main_pane.add(chat_frame)\n        main_pane.add(code_frame)\n\n        # ----------------------\n        # Input Box\n        # ----------------------\n        self.input_box = tk.Text(self.root, height=5, wrap=\"word\")\n        self.input_box.grid(row=2, column=0, sticky=\"nsew\")\n\n        self.root.update_idletasks()\n        main_pane.sashpos(0, int(self.root.winfo_width() * 0.70))\n    \n    def _get_client_for_model(self, model: str):\n        \"\"\"Return the appropriate client for the given model.\"\"\"\n        if model in OPENAI_MODELS:\n            return openai_client\n        else:\n            return groq_client\n    \n    def _get_max_tokens_for_model(self, model: str):\n        \"\"\"Return appropriate max_tokens for the given model.\"\"\"\n        if model in OPENAI_MODELS:\n            return 16000\n        else:\n            return 8000\n    \n    def _uses_max_completion_tokens(self, model: str):\n        \"\"\"Check if model uses max_completion_tokens instead of max_tokens.\"\"\"\n        return model in [\"gpt-5.2\", \"gpt-5-mini\"]\n\n    def _bind_keys(self):\n        self.input_box.bind(\"<Return>\", self._on_enter)\n        self.input_box.bind(\"<Shift-Return>\", lambda e: None)\n    \n    def _on_code_modified(self, event):\n        \"\"\"Sync code_contents when user edits the code panel.\"\"\"\n        if self.code_panel.edit_modified():\n            self.code_contents = self.code_panel.get(\"1.0\", \"end-1c\")\n            self.code_panel.edit_modified(False)\n\n    # -----------------------------\n    # Input\n    # -----------------------------\n\n    def _on_enter(self, event):\n        if self.is_generating:\n            return \"break\"\n\n        text = self.input_box.get(\"1.0\", \"end-1c\").strip()\n        if not text:\n            return \"break\"\n\n        self.input_box.delete(\"1.0\", \"end\")\n        self._append_chat(\"You\", text)\n        \n        # Add user message to conversation\n        self.conversation.append({\"role\": \"user\", \"content\": text})\n        \n        # Add invisible context about current code if it exists\n        if self.code_contents.strip():\n            self.conversation.append({\n                \"role\": \"user\",\n                \"content\": f\"Here's my current code:\\n{self.code_contents}\"\n            })\n\n        self._start_generation()\n        return \"break\"\n\n    # -----------------------------\n    # Chat Generation\n    # -----------------------------\n\n    def _start_generation(self):\n        self.is_generating = True\n        self.input_box.configure(state=\"disabled\")\n        self.current_assistant_buffer = \"\"\n\n        threading.Thread(\n            target=self._stream_chat_response, daemon=True\n        ).start()\n\n    def _stream_chat_response(self):\n        try:\n            model = self.chat_model.get()\n            client = self._get_client_for_model(model)\n            max_tokens = self._get_max_tokens_for_model(model)\n            \n            # Build request parameters\n            params = {\n                \"model\": model,\n                \"messages\": self.conversation,\n                \"stream\": True,\n            }\n            \n            # Use max_completion_tokens for GPT-5.2 and GPT-5-mini\n            if self._uses_max_completion_tokens(model):\n                params[\"max_completion_tokens\"] = max_tokens\n            else:\n                params[\"max_tokens\"] = max_tokens\n            \n            stream = client.chat.completions.create(**params)\n\n            for chunk in stream:\n                delta = chunk.choices[0].delta.content or \"\"\n                if delta:\n                    self.token_queue.put(delta)\n\n        except Exception as e:\n            self.token_queue.put(f\"\\n[Error: {e}]\")\n\n        finally:\n            self.token_queue.put(None)\n\n    def _poll_tokens(self):\n        try:\n            while True:\n                token = self.token_queue.get_nowait()\n\n                if token is None:\n                    self._finalize_assistant_message()\n                    break\n\n                self.current_assistant_buffer += token\n                self._append_to_last_chat(token)\n\n        except queue.Empty:\n            pass\n\n        self.root.after(20, self._poll_tokens)\n\n    def _finalize_assistant_message(self):\n        assistant_text = self.current_assistant_buffer\n        self.conversation.append({\"role\": \"assistant\", \"content\": assistant_text})\n\n        self.is_generating = False\n        self.input_box.configure(state=\"normal\")\n\n        # Replace the streaming label with parsed content\n        self._replace_with_parsed_message(assistant_text)\n\n    def _replace_with_parsed_message(self, text: str):\n        \"\"\"Parse the message and replace code blocks with interactive widgets.\"\"\"\n        if self.current_message_label:\n            self.current_message_label.destroy()\n            self.current_message_label = None\n\n        # Create a container for this message\n        message_container = ttk.Frame(self.chat_inner_frame)\n        message_container.pack(fill=\"x\", padx=5, pady=5)\n\n        # Add sender as copyable text\n        sender_text = tk.Text(\n            message_container,\n            height=1,\n            wrap=\"none\",\n            font=(\"TkDefaultFont\", 10, \"bold\"),\n            relief=\"flat\",\n            background=self.bg_color\n        )\n        sender_text.insert(\"1.0\", \"Assistant:\")\n        sender_text.configure(state=\"disabled\")\n        sender_text.pack(fill=\"x\")\n\n        # Split text by code blocks\n        parts = self._split_text_and_code(text)\n        \n        for part_type, content in parts:\n            if part_type == \"text\":\n                if content.strip():\n                    text_widget = tk.Text(\n                        message_container,\n                        height=content.count(\"\\n\") + 1 + int(len(content) * 0.012),\n                        wrap=\"word\",\n                        relief=\"flat\",\n                        background=self.bg_color\n                    )\n                    text_widget.insert(\"1.0\", content)\n                    text_widget.configure(state=\"disabled\")\n                    text_widget.pack(fill=\"x\", padx=5, pady=2)\n            elif part_type == \"code\":\n                proposal = CodeProposal(\n                    parent=message_container,\n                    code=content,\n                    on_replace=self._replace_code_panel,\n                    on_add=self._add_code_via_helper,\n                )\n                proposal.pack(fill=\"x\", pady=5)\n\n        # Scroll to bottom\n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n\n    def _split_text_and_code(self, text: str):\n        \"\"\"Split text into alternating text and code blocks.\"\"\"\n        parts = []\n        last_end = 0\n        \n        for match in CODE_BLOCK_REGEX.finditer(text):\n            # Add text before code block\n            if match.start() > last_end:\n                parts.append((\"text\", text[last_end:match.start()]))\n            \n            # Add code block\n            parts.append((\"code\", match.group(1)))\n            last_end = match.end()\n        \n        # Add remaining text after last code block\n        if last_end < len(text):\n            parts.append((\"text\", text[last_end:]))\n        \n        return parts\n\n    # -----------------------------\n    # Code Handling (Line-Number Based Approach)\n    # -----------------------------\n\n    def _add_line_numbers(self, code: str) -> str:\n        \"\"\"Prepend line numbers to each line of code.\"\"\"\n        lines = code.split(\"\\n\")\n        numbered_lines = [f\"{i+1} | {line}\" for i, line in enumerate(lines)]\n        return \"\\n\".join(numbered_lines)\n\n    def _add_code_via_helper(self, new_code: str):\n        \"\"\"Apply new code safely. If new_code contains top-level defs/classes, replace the existing block(s) instead of inserting.\"\"\"\n        if not self.code_contents.strip():\n            self._replace_code_panel(new_code)\n            return\n\n        blocks = self._extract_top_level_blocks(new_code)\n\n        # If the assistant gave us a full function/class, do a safe structural replace.\n        if blocks:\n            try:\n                updated = self.code_contents\n                for name, block_text in blocks:\n                    updated = self._replace_top_level_block_by_name(updated, name, block_text)\n\n                self._assert_no_duplicate_block_defs(updated, blocks)\n\n                self.code_contents = updated\n                self.code_panel.delete(\"1.0\", \"end\")\n                self.code_panel.insert(\"1.0\", updated)\n                self._append_chat(\"System\", \"Code updated successfully (structural replace)!\")\n                return\n            except Exception as e:\n                self._append_chat(\"System\", f\"Structural replace failed, falling back to helper insertion: {e}\")\n\n        # Fallback: original line-based helper insertion (good for small snippets that aren't whole defs/classes)\n        insertion_data = self._get_insertion_instructions(new_code)\n\n        if not insertion_data:\n            self._append_chat(\"System\", \"Helper model did not return valid instructions.\")\n            return\n\n        try:\n            updated_code = self._apply_line_based_edit(\n                insertion_data[\"insertion_point\"],\n                insertion_data[\"delete_lines\"],\n                new_code,\n                insertion_data[\"indent_spaces\"]\n            )\n            self.code_contents = updated_code\n            self.code_panel.delete(\"1.0\", \"end\")\n            self.code_panel.insert(\"1.0\", updated_code)\n            self._append_chat(\"System\", \"Code updated successfully!\")\n        except Exception as e:\n            self._append_chat(\"System\", f\"Edit failed: {e}\")\n\n\n    def _extract_top_level_blocks(self, code: str) -> list[tuple[str, str]]:\n        \"\"\"\n        Return list of (name, block_text) for top-level `def name(...):` and `class Name...:`.\n        Only matches blocks that start at column 0.\n        \"\"\"\n        lines = code.splitlines(True)  # keep line endings\n        starts = []\n        for i, line in enumerate(lines):\n            m = re.match(r'^(def|class)\\s+([A-Za-z_][A-Za-z0-9_]*)\\b.*:\\s*(#.*)?\\n?$', line)\n            if m:\n                starts.append((i, m.group(2)))\n\n        blocks: list[tuple[str, str]] = []\n        for idx, (start_i, name) in enumerate(starts):\n            end_i = starts[idx + 1][0] if idx + 1 < len(starts) else len(lines)\n            block_text = \"\".join(lines[start_i:end_i]).rstrip(\"\\n\")\n            blocks.append((name, block_text))\n        return blocks\n\n\n    def _replace_top_level_block_by_name(self, original: str, name: str, new_block: str) -> str:\n        \"\"\"\n        Replace the first top-level `def name` or `class name` block in original with new_block.\n        A block is from its `def/class` line at column 0 up to (but not including) the next top-level def/class line.\n        \"\"\"\n        lines = original.splitlines(True)  # keep line endings\n\n        # Find block start\n        start_i = None\n        for i, line in enumerate(lines):\n            if re.match(rf'^(def|class)\\s+{re.escape(name)}\\b.*:\\s*(#.*)?\\n?$', line):\n                start_i = i\n                break\n\n        if start_i is None:\n            raise ValueError(f\"Could not find existing top-level def/class named '{name}' to replace.\")\n\n        # Find block end\n        end_i = len(lines)\n        for j in range(start_i + 1, len(lines)):\n            if re.match(r'^(def|class)\\s+[A-Za-z_][A-Za-z0-9_]*\\b.*:\\s*(#.*)?\\n?$', lines[j]):\n                end_i = j\n                break\n\n        # Preserve a single trailing newline style around the replacement\n        replacement = new_block.rstrip(\"\\n\") + \"\\n\"\n        new_lines = lines[:start_i] + [replacement] + lines[end_i:]\n        return \"\".join(new_lines)\n\n\n    def _assert_no_duplicate_block_defs(self, updated: str, replaced_blocks: list[tuple[str, str]]) -> None:\n        \"\"\"\n        Ensure we didn't create duplicate top-level defs/classes for any replaced name.\n        \"\"\"\n        for name, _block in replaced_blocks:\n            occurrences = len(re.findall(rf'^(def|class)\\s+{re.escape(name)}\\b', updated, flags=re.MULTILINE))\n            if occurrences != 1:\n                raise ValueError(f\"After edit, expected exactly 1 top-level definition for '{name}', found {occurrences}.\")\n\n\n    def _get_insertion_instructions(self, new_code: str) -> dict | None:\n        \"\"\"Ask helper model for insertion point and lines to delete using line numbers, with verification.\"\"\"\n        # Add line numbers to current code\n        numbered_code = self._add_line_numbers(self.code_contents)\n        \n        system_prompt = (\n            \"You are a code editing assistant. Your job is to determine where to insert new code \"\n            \"and which lines (if any) to delete from the existing code.\\n\\n\"\n            \"You will receive:\\n\"\n            \"1. The current code with line numbers (format: '1 | code here')\\n\"\n            \"2. New code to insert\\n\\n\"\n            \"You must respond ONLY with JSON in this exact format:\\n\"\n            \"{\\n\"\n            '  \"insertion_point\": <line_number>,\\n'\n            '  \"delete_lines\": [<line_numbers>],\\n'\n            '  \"indent_spaces\": <number_of_spaces>\\n'\n            \"}\\n\\n\"\n            \"Rules:\\n\"\n            \"- insertion_point: The line number AFTER which to insert the new code (use 0 to insert at the beginning)\\n\"\n            \"- delete_lines: Array of line numbers to delete (can be empty [] if just inserting)\\n\"\n            \"- indent_spaces: Number of spaces to add to the beginning of each line of inserted code (to match surrounding indentation)\\n\"\n            \"- Use the CURRENT line numbers you see - don't worry about how insertion affects numbering\\n\"\n            \"- If replacing code, include those line numbers in delete_lines\\n\"\n            \"- If just inserting, leave delete_lines empty\\n\"\n            \"- Look at the indentation of surrounding code to determine indent_spaces\\n\\n\"\n            \"Example 1 - Replace lines 5-7 with 8 spaces of indentation:\\n\"\n            '{\"insertion_point\": 4, \"delete_lines\": [5, 6, 7], \"indent_spaces\": 8}\\n\\n'\n            \"Example 2 - Insert after line 10 with 4 spaces:\\n\"\n            '{\"insertion_point\": 10, \"delete_lines\": [], \"indent_spaces\": 4}\\n\\n'\n            \"Example 3 - Insert at beginning with no indentation:\\n\"\n            '{\"insertion_point\": 0, \"delete_lines\": [], \"indent_spaces\": 0}\\n\\n'\n            \"Respond with ONLY the JSON, no explanations.\"\n        )\n\n        user_prompt = (\n            \"CURRENT CODE (with line numbers):\\n\"\n            f\"{numbered_code}\\n\\n\"\n            \"NEW CODE TO INSERT:\\n\"\n            f\"{new_code}\\n\"\n        )\n\n        model = self.helper_model.get()\n        client = self._get_client_for_model(model)\n        max_tokens = self._get_max_tokens_for_model(model)\n        \n        # First attempt\n        conversation = [\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ]\n        \n        data = self._call_helper_and_parse(client, model, max_tokens, conversation)\n        \n        if not data:\n            return None\n        \n        print(\"First attempt JSON:\", data)\n        \n        # Apply the edit and show result to model for verification\n        try:\n            updated_code = self._apply_line_based_edit(\n                data[\"insertion_point\"],\n                data[\"delete_lines\"],\n                new_code,\n                data[\"indent_spaces\"]\n            )\n            \n            # Show the result to the model for verification\n            numbered_result = self._add_line_numbers(updated_code)\n            \n            verification_prompt = (\n                \"Here is the result of applying your edit instructions:\\n\\n\"\n                f\"{numbered_result}\\n\\n\"\n                \"Does this look correct? Did the new code get inserted in the right place with proper indentation?\\n\"\n                \"If YES, respond with just: CORRECT\\n\"\n                \"If NO, provide a corrected JSON with the right insertion_point, delete_lines, and indent_spaces.\\n\"\n                \"Remember the original code had these line numbers:\\n\"\n                f\"{numbered_code}\\n\"\n            )\n            \n            conversation.append({\"role\": \"assistant\", \"content\": json.dumps(data)})\n            conversation.append({\"role\": \"user\", \"content\": verification_prompt})\n            \n            params = {\n                \"model\": model,\n                \"messages\": conversation,\n            }\n            \n            if self._uses_max_completion_tokens(model):\n                params[\"max_completion_tokens\"] = max_tokens\n            else:\n                params[\"max_tokens\"] = max_tokens\n            \n            verification_response = client.chat.completions.create(**params)\n            verification_text = verification_response.choices[0].message.content or \"\"\n            \n            print(\"Verification response:\", verification_text)\n            \n            # Check if model says it's correct\n            if \"CORRECT\" in verification_text.upper():\n                print(\"Model verified the edit is correct\")\n                return data\n            \n            # Try to extract corrected JSON\n            corrected_data = self._extract_json_from_text(verification_text)\n            \n            if corrected_data and self._validate_json_format(corrected_data):\n                print(\"Second attempt JSON:\", corrected_data)\n                return corrected_data\n            \n            # If no valid correction, return original\n            print(\"No valid correction provided, using original\")\n            return data\n            \n        except Exception as e:\n            print(f\"Error during verification: {e}\")\n            return data\n\n    def _call_helper_and_parse(self, client, model: str, max_tokens: int, conversation: list) -> dict | None:\n        \"\"\"Call the helper model and parse JSON response.\"\"\"\n        params = {\n            \"model\": model,\n            \"messages\": conversation,\n        }\n        \n        if self._uses_max_completion_tokens(model):\n            params[\"max_completion_tokens\"] = max_tokens\n        else:\n            params[\"max_tokens\"] = max_tokens\n        \n        try:\n            response = client.chat.completions.create(**params)\n            response_text = response.choices[0].message.content or \"\"\n            \n            print(\"Helper response:\", response_text)\n            \n            return self._extract_json_from_text(response_text)\n            \n        except Exception as e:\n            print(f\"Error calling helper: {e}\")\n            return None\n    \n    def _extract_json_from_text(self, text: str) -> dict | None:\n        \"\"\"Extract and parse JSON from text that may contain markdown or other content.\"\"\"\n        # Try to find JSON in the text\n        json_match = re.search(r'\\{[^}]+\\}', text, re.DOTALL)\n        if json_match:\n            text = json_match.group(0)\n        \n        try:\n            data = json.loads(text)\n            if self._validate_json_format(data):\n                return data\n        except:\n            pass\n        \n        return None\n    \n    def _validate_json_format(self, data: dict) -> bool:\n        \"\"\"Validate that JSON has required fields with correct types.\"\"\"\n        if \"insertion_point\" not in data or \"delete_lines\" not in data or \"indent_spaces\" not in data:\n            return False\n        \n        if not isinstance(data[\"insertion_point\"], int):\n            return False\n        \n        if not isinstance(data[\"delete_lines\"], list):\n            return False\n        \n        if not isinstance(data[\"indent_spaces\"], int):\n            return False\n        \n        return True\n\n    def _apply_line_based_edit(self, insertion_point: int, delete_lines: list, new_code: str, indent_spaces: int) -> str:\n        \"\"\"Apply insertion and deletion based on line numbers, with indentation.\"\"\"\n        lines = self.code_contents.split(\"\\n\")\n        \n        # Validate line numbers\n        if insertion_point < 0 or insertion_point > len(lines):\n            raise ValueError(f\"Invalid insertion point: {insertion_point}\")\n        \n        for line_num in delete_lines:\n            if line_num < 1 or line_num > len(lines):\n                raise ValueError(f\"Invalid line number to delete: {line_num}\")\n        \n        # Convert delete_lines to 0-indexed and sort in reverse order\n        delete_indices = sorted([line_num - 1 for line_num in delete_lines], reverse=True)\n        \n        # Adjust insertion point if we're deleting lines before it\n        adjusted_insertion = insertion_point\n        for idx in delete_indices:\n            if idx < insertion_point:\n                adjusted_insertion -= 1\n        \n        # Delete lines (in reverse order to preserve indices)\n        for idx in delete_indices:\n            del lines[idx]\n        \n        # Apply indentation to new code\n        indent = \" \" * indent_spaces\n        new_lines = new_code.split(\"\\n\")\n        indented_lines = [indent + line for line in new_lines]\n        \n        # Insert new code at the adjusted position\n        lines[adjusted_insertion:adjusted_insertion] = indented_lines\n        \n        return \"\\n\".join(lines)\n\n    def _replace_code_panel(self, code: str):\n        self.code_contents = code\n        self.code_panel.delete(\"1.0\", \"end\")\n        self.code_panel.insert(\"1.0\", code)\n\n    # -----------------------------\n    # Persistence\n    # -----------------------------\n    def save_conversation(self, path: str | None = None):\n        if path is None:\n            path = filedialog.asksaveasfilename(\n                defaultextension=\".json\",\n                filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")]\n            )\n            if not path:\n                return\n        try:\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(self.conversation, f, indent=2, ensure_ascii=False)\n            self.auto_save_path = path\n            messagebox.showinfo(\"Saved\", f\"Conversation saved to\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Save error\", str(e))\n\n    def load_conversation(self):\n        path = filedialog.askopenfilename(\n            defaultextension=\".json\",\n            filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")]\n        )\n        if not path:\n            return\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                loaded = json.load(f)\n            if not isinstance(loaded, list):\n                raise ValueError(\"File must contain a list of messages.\")\n            self.conversation = loaded\n            self.auto_save_path = path\n            self._redraw_chat()\n            messagebox.showinfo(\"Loaded\", f\"Conversation loaded from\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Load error\", str(e))\n\n    def export_markdown(self):\n        path = filedialog.asksaveasfilename(\n            defaultextension=\".md\",\n            filetypes=[(\"Markdown files\", \"*.md\"), (\"All files\", \"*.*\")]\n        )\n        if not path:\n            return\n        try:\n            lines = []\n            for msg in self.conversation:\n                role = msg.get(\"role\", \"\")\n                content = msg.get(\"content\", \"\")\n                if role == \"system\":\n                    continue\n                name = \"You\" if role == \"user\" else \"Assistant\"\n                lines.append(f\"**{name}:**\\n{content}\\n\")\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"\\n\".join(lines))\n            messagebox.showinfo(\"Exported\", f\"Markdown exported to\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Export error\", str(e))\n\n    def _redraw_chat(self):\n        for w in self.chat_inner_frame.winfo_children():\n            w.destroy()\n        self.current_message_label = None\n        for msg in self.conversation:\n            role = msg.get(\"role\")\n            content = msg.get(\"content\", \"\")\n            if role == \"system\":\n                continue\n            sender = \"You\" if role == \"user\" else \"Assistant\"\n            if role == \"assistant\":\n                self._replace_with_parsed_message(content)\n            else:\n                self._append_chat(sender, content)\n\n    # -----------------------------\n    # UI Helpers\n    # -----------------------------\n\n    def _append_chat(self, sender: str, text: str):\n        \"\"\"Modified for tighter user message spacing.\"\"\"\n        container = ttk.Frame(self.chat_inner_frame)\n        container.pack(fill=\"x\", padx=10, pady=5)\n    \n        header = tk.Label(container, text=f\"{sender}:\", font=(\"TkDefaultFont\", 10, \"bold\"),\n                         bg=self.bg_color)\n        header.pack(fill=\"x\")\n    \n        # Dynamic height for content\n        line_count = text.count(\"\\n\") + 1\n        body = tk.Label(container, text=text, wraplength=800,\n                      justify=\"left\", bg=self.bg_color)\n        body.pack(fill=\"x\", padx=5)\n        \n        if sender == \"Assistant\":\n            self.current_message_label = body\n            self.current_message_container = container\n    \n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n    \n    def _append_to_last_chat(self, text: str):\n        \"\"\"Append text and grow the text widget height dynamically.\"\"\"\n        if self.current_message_label:\n            self.current_message_label.configure(state=\"normal\")\n            self.current_message_label.insert(\"end\", text)\n            \n            line_count = int(self.current_message_label.index(\"end-1c\").split(\".\")[0])\n            self.current_message_label.configure(height=line_count, state=\"disabled\")\n            \n            self.chat_canvas.update_idletasks()\n            self.chat_canvas.yview_moveto(1.0)\n\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    ChatUI(root)\n    root.mainloop()\n\n"
  },
  {
    "role": "assistant",
    "content": "Here's an improvement to the provided code:\n```python\ndef _split_text_and_code(self, text: str) -> list[tuple[str, str]]:\n    \"\"\"Split text into alternating text and code blocks.\"\"\"\n    parts = []\n    last_end = 0\n    \n    # Use non-overlapping findall to get all matches\n    for match in CODE_BLOCK_REGEX.finditer(text):\n        # Add text before code block\n        if match.start() > last_end:\n            parts.append((\"text\", text[last_end:match.start()]))\n        \n        # Add code block\n        parts.append((\"code\", match.group(1)))\n        last_end = match.end()\n        \n    # Add remaining text after last code block\n    if last_end < len(text):\n        parts.append((\"text\", text[last_end:]))\n        \n    return parts\n```\nThis code now correctly splits the input text into alternating text and code blocks. The `CODE_BLOCK_REGEX.finditer(text)` finds all occurrences of code blocks in the text without overlapping. \n\nHowever, a bigger improvement could be made to reduce repetition throughout the code, by encapsulating the code for creating a new message frame into its own function. Here is an example:\n```python\ndef _create_message_frame(self, sender: str, text: str):\n    container = ttk.Frame(self.chat_inner_frame)\n    container.pack(fill=\"x\", padx=10, pady=5)\n    \n    header = tk.Label(container, text=f\"{sender}:\", font=(\"TkDefaultFont\", 10, \"bold\"),\n                     bg=self.bg_color)\n    header.pack(fill=\"x\")\n    \n    # Dynamic height for content\n    line_count = text.count(\"\\n\") + 1\n    body = tk.Label(container, text=text, wraplength=800,\n                  justify=\"left\", bg=self.bg_color)\n    body.pack(fill=\"x\", padx=5)\n    \n    return body, container\n\ndef _append_chat(self, sender: str, text: str):\n    \"\"\"Modified for tighter user message spacing.\"\"\"\n    body, container = self._create_message_frame(sender, text)\n    \n    if sender == \"Assistant\":\n        self.current_message_label = body\n        self.current_message_container = container\n    \n    self.chat_canvas.update_idletasks()\n    self.chat_canvas.yview_moveto(1.0)\n\ndef _replace_with_parsed_message(self, text: str):\n    \"\"\"Parse the message and replace code blocks with interactive widgets.\"\"\"\n    if self.current_message_label:\n        self.current_message_label.destroy()\n        self.current_message_label = None\n\n    # Create a container for this message\n    message_container = ttk.Frame(self.chat_inner_frame)\n    message_container.pack(fill=\"x\", padx=5, pady=5)\n\n    # Add sender as copyable text\n    sender_text = tk.Text(\n        message_container,\n        height=1,\n        wrap=\"none\",\n        font=(\"TkDefaultFont\", 10, \"bold\"),\n        relief=\"flat\",\n        background=self.bg_color\n    )\n    sender_text.insert(\"1.0\", \"Assistant:\")\n    sender_text.configure(state=\"disabled\")\n    sender_text.pack(fill=\"x\")\n\n    # Split text by code blocks\n    parts = self._split_text_and_code(text)\n    \n    for part_type, content in parts:\n        if part_type == \"text\":\n            if content.strip():\n                body, _ = self._create_message_frame(\"Assistant\", content)\n        elif part_type == \"code\":\n            proposal = CodeProposal(\n                parent=message_container,\n                code=content,\n                on_replace=self._replace_code_panel,\n                on_add=self._add_code_via_helper,\n            )\n            proposal.pack(fill=\"x\", pady=5)\n\n    # Scroll to bottom\n    self.chat_canvas.update_idletasks()\n    self.chat_canvas.yview_moveto(1.0)\n```"
  },
  {
    "role": "user",
    "content": "Reducing repetition is a great idea. Look at my code and suggest the changes needed to finish the job please."
  },
  {
    "role": "user",
    "content": "Here's my current code:\nimport os\nimport re\nimport threading\nimport queue\nimport tkinter as tk\nfrom tkinter import ttk, filedialog, messagebox\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nimport json\n\n# -----------------------------\n# Environment / Client Setup\n# -----------------------------\n\nload_dotenv()\n\ngroq_client = OpenAI(\n    api_key=os.getenv(\"GROQ_API_KEY\"),\n    base_url=\"https://api.groq.com/openai/v1\",\n)\n\nopenai_client = OpenAI(\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n)\n\n# Model configurations\nGROQ_MODELS = [\n    \"llama-3.3-70b-versatile\",\n    \"moonshotai/kimi-k2-instruct\",\n    \"moonshotai/kimi-k2-instruct-0905\",\n    \"openai/gpt-oss-120b\",\n    \"openai/gpt-oss-20b\",\n    \"meta-llama/llama-4-maverick-17b-128e-instruct\",\n]\n\nOPENAI_MODELS = [\n    \"gpt-5.2\",\n    \"gpt-5-mini\",\n    \"gpt-4.1\",\n]\n\nALL_MODELS = GROQ_MODELS + OPENAI_MODELS\n\nCODE_BLOCK_REGEX = re.compile(\n    r\"```(?:\\w+)?\\s*(.*?)```\",\n    re.DOTALL\n)\n\n# -----------------------------\n# UI\n# -----------------------------\nclass CodeProposal(ttk.Frame):\n    def __init__(self, parent, code: str, on_replace, on_add):\n        super().__init__(parent)\n        self.code = code\n\n        # Calculate height: number of lines + 1\n        line_count = code.count(\"\\n\") + 1\n        \n        self.text = tk.Text(\n            self,\n            height=line_count,\n            wrap=\"none\",\n            font=(\"Courier New\", 10),\n            padx=5,\n            pady=5,\n            highlightthickness=1 # Border for code blocks\n        )\n        self.text.insert(\"1.0\", code)\n        self.text.configure(state=\"disabled\")\n        self.text.pack(fill=\"x\", padx=5, pady=(5, 2))\n\n        button_row = ttk.Frame(self)\n        button_row.pack(anchor=\"e\", padx=5, pady=(0, 5))\n\n        ttk.Button(button_row, text=\"Replace\", command=lambda: on_replace(code)).pack(side=\"right\", padx=2)\n        ttk.Button(button_row, text=\"Add\", command=lambda: on_add(code)).pack(side=\"right\", padx=2)\n\nclass ChatUI:\n    def __init__(self, root: tk.Tk):\n        self.root = root\n        self.root.title(\"Chat + Code UI\")\n        self.root.geometry(\"1100x650\")\n\n        self.conversation = [\n            {\"role\": \"system\", \"content\": \"\"\"\nYou are a coding assistant inside a UI that extracts and applies code blocks verbatim. The user may copy/paste code blocks directly into files. Therefore, code blocks must be **complete, explicit, and directly runnable** (or clearly minimal but still syntactically valid).  \n\n**Critical rule: Never use placeholder elisions** in code blocks or patch instructions. This includes (but is not limited to):  \n- `...` or `…`  \n- `# ...` / `// ...` / `/* ... */`  \n- “(other code)”, “existing code”, “rest of file”, “unchanged”, “omitted”, “same as above/below”  \n- “insert here”, “fill in”, “TODO: add …” (unless the user explicitly asked for TODOs)\n\nIf a full-file rewrite would be too long, do **one** of these instead:\n1) Output **multiple complete code blocks** representing each full function/class/module that must be added or replaced, and explicitly name what each block replaces; or  \n2) Ask a **single clarifying question** to reduce scope so you can provide complete code.\n\nWhen you provide code edits:\n- Ensure the code in each fenced block is self-contained and contains all required imports/definitions for that block to work as presented.  \n- If you reference “add this to X”, you must show the exact insertion target by function/class name (and if needed, quote the exact original lines you’re replacing) — but do not use ellipses.\n\nFormatting rules:\n- Critical rule: Never use placeholder comments to represent code that has already been written\n- Use fenced code blocks only for real code or real patches.\n- If you cannot comply with the no-elision rule, stop and ask for the missing file/context instead of guessing.\n             \"\"\"}\n        ]\n\n        self.token_queue = queue.Queue()\n        self.is_generating = False\n        self.current_assistant_buffer = \"\"\n\n        self.code_contents = \"\"\n\n        # ---- persistence helpers ----\n        self.auto_save_path: str | None = None\n        self.auto_save_after_id: str | None = None\n        self.auto_save_interval_ms = 30_000\n        \n        # Default models\n        self.chat_model = tk.StringVar(value=\"llama-3.3-70b-versatile\")\n        self.helper_model = tk.StringVar(value=\"llama-3.3-70b-versatile\")\n\n        self._build_layout()\n        self._bind_keys()\n        self._poll_tokens()\n\n    # -----------------------------\n    # Layout\n    # -----------------------------\n\n    def _build_layout(self) -> None:\n        self.root.rowconfigure(0, weight=0)\n        self.root.rowconfigure(1, weight=1)\n        self.root.rowconfigure(2, weight=0)\n        self.root.columnconfigure(0, weight=1)\n\n        # ----------------------\n        # Model Selection Bar\n        # ----------------------\n        model_frame = ttk.Frame(self.root)\n        model_frame.grid(row=0, column=0, sticky=\"ew\", padx=5, pady=5)\n        \n        ttk.Label(model_frame, text=\"Chat Model:\").pack(side=\"left\", padx=(0, 5))\n        chat_dropdown = ttk.Combobox(\n            model_frame,\n            textvariable=self.chat_model,\n            values=ALL_MODELS,\n            state=\"readonly\",\n            width=40\n        )\n        chat_dropdown.pack(side=\"left\", padx=(0, 20))\n        \n        ttk.Label(model_frame, text=\"Helper Model:\").pack(side=\"left\", padx=(0, 5))\n        helper_dropdown = ttk.Combobox(\n            model_frame,\n            textvariable=self.helper_model,\n            values=ALL_MODELS,\n            state=\"readonly\",\n            width=40\n        )\n        helper_dropdown.pack(side=\"left\")\n\n        # ----------------------\n        # Menu bar\n        # ----------------------\n        menubar = tk.Menu(self.root)\n        file_menu = tk.Menu(menubar, tearoff=0)\n        file_menu.add_command(label=\"Save conversation…\", command=self.save_conversation)\n        file_menu.add_command(label=\"Load conversation…\", command=self.load_conversation)\n        file_menu.add_separator()\n        file_menu.add_command(label=\"Export markdown…\", command=self.export_markdown)\n        menubar.add_cascade(label=\"File\", menu=file_menu)\n        self.root.config(menu=menubar)\n\n        main_pane = ttk.PanedWindow(self.root, orient=\"horizontal\")\n        main_pane.grid(row=1, column=0, sticky=\"nsew\")\n\n        # ----------------------\n        # Chat + Code Proposals\n        # ----------------------\n        chat_frame = ttk.Frame(main_pane)\n        chat_frame.rowconfigure(0, weight=1)\n        chat_frame.columnconfigure(0, weight=1)\n\n        # Scrollable canvas\n        self.chat_canvas = tk.Canvas(chat_frame)\n        self.chat_scrollbar = ttk.Scrollbar(chat_frame, command=self.chat_canvas.yview)\n        self.chat_canvas.configure(yscrollcommand=self.chat_scrollbar.set)\n\n        self.chat_scrollbar.grid(row=0, column=1, sticky=\"ns\")\n        self.chat_canvas.grid(row=0, column=0, sticky=\"nsew\")\n\n        # Inner frame to hold all messages\n        self.chat_inner_frame = ttk.Frame(self.chat_canvas)\n        self.chat_canvas.create_window((0, 0), window=self.chat_inner_frame, anchor=\"nw\")\n\n        # Update scroll region when content changes\n        self.chat_inner_frame.bind(\n            \"<Configure>\",\n            lambda e: self.chat_canvas.configure(scrollregion=self.chat_canvas.bbox(\"all\"))\n        )\n\n        # Track the current message label for streaming\n        self.current_message_label = None\n        \n        # Get background color from a standard widget\n        self.bg_color = self.root.cget(\"background\")\n\n        # ----------------------\n        # Code Panel\n        # ----------------------\n        code_frame = ttk.Frame(main_pane)\n        code_frame.rowconfigure(0, weight=1)\n        code_frame.columnconfigure(0, weight=1)\n\n        self.code_panel = tk.Text(code_frame, wrap=\"none\")\n        self.code_panel.grid(row=0, column=0, sticky=\"nsew\")\n        \n        # Bind to sync code_contents when user edits\n        self.code_panel.bind(\"<<Modified>>\", self._on_code_modified)\n\n        # Add this line to bind Ctrl+A to select all code\n        self.code_panel.bind(\"<Control-a>\", lambda e: (self.code_panel.tag_add(\"sel\", \"1.0\", \"end\"), \"break\")[1])\n        \n        code_scroll = ttk.Scrollbar(code_frame, command=self.code_panel.yview)\n        code_scroll.grid(row=0, column=1, sticky=\"ns\")\n        self.code_panel[\"yscrollcommand\"] = code_scroll.set\n\n        main_pane.add(chat_frame)\n        main_pane.add(code_frame)\n\n        # ----------------------\n        # Input Box\n        # ----------------------\n        self.input_box = tk.Text(self.root, height=5, wrap=\"word\")\n        self.input_box.grid(row=2, column=0, sticky=\"nsew\")\n\n        self.root.update_idletasks()\n        main_pane.sashpos(0, int(self.root.winfo_width() * 0.70))\n    \n    def _get_client_for_model(self, model: str):\n        \"\"\"Return the appropriate client for the given model.\"\"\"\n        if model in OPENAI_MODELS:\n            return openai_client\n        else:\n            return groq_client\n    \n    def _get_max_tokens_for_model(self, model: str):\n        \"\"\"Return appropriate max_tokens for the given model.\"\"\"\n        if model in OPENAI_MODELS:\n            return 16000\n        else:\n            return 8000\n    \n    def _uses_max_completion_tokens(self, model: str):\n        \"\"\"Check if model uses max_completion_tokens instead of max_tokens.\"\"\"\n        return model in [\"gpt-5.2\", \"gpt-5-mini\"]\n\n    def _bind_keys(self):\n        self.input_box.bind(\"<Return>\", self._on_enter)\n        self.input_box.bind(\"<Shift-Return>\", lambda e: None)\n    \n    def _on_code_modified(self, event):\n        \"\"\"Sync code_contents when user edits the code panel.\"\"\"\n        if self.code_panel.edit_modified():\n            self.code_contents = self.code_panel.get(\"1.0\", \"end-1c\")\n            self.code_panel.edit_modified(False)\n\n    # -----------------------------\n    # Input\n    # -----------------------------\n\n    def _on_enter(self, event):\n        if self.is_generating:\n            return \"break\"\n\n        text = self.input_box.get(\"1.0\", \"end-1c\").strip()\n        if not text:\n            return \"break\"\n\n        self.input_box.delete(\"1.0\", \"end\")\n        self._append_chat(\"You\", text)\n        \n        # Add user message to conversation\n        self.conversation.append({\"role\": \"user\", \"content\": text})\n        \n        # Add invisible context about current code if it exists\n        if self.code_contents.strip():\n            self.conversation.append({\n                \"role\": \"user\",\n                \"content\": f\"Here's my current code:\\n{self.code_contents}\"\n            })\n\n        self._start_generation()\n        return \"break\"\n\n    # -----------------------------\n    # Chat Generation\n    # -----------------------------\n\n    def _start_generation(self):\n        self.is_generating = True\n        self.input_box.configure(state=\"disabled\")\n        self.current_assistant_buffer = \"\"\n\n        threading.Thread(\n            target=self._stream_chat_response, daemon=True\n        ).start()\n\n    def _stream_chat_response(self):\n        try:\n            model = self.chat_model.get()\n            client = self._get_client_for_model(model)\n            max_tokens = self._get_max_tokens_for_model(model)\n            \n            # Build request parameters\n            params = {\n                \"model\": model,\n                \"messages\": self.conversation,\n                \"stream\": True,\n            }\n            \n            # Use max_completion_tokens for GPT-5.2 and GPT-5-mini\n            if self._uses_max_completion_tokens(model):\n                params[\"max_completion_tokens\"] = max_tokens\n            else:\n                params[\"max_tokens\"] = max_tokens\n            \n            stream = client.chat.completions.create(**params)\n\n            for chunk in stream:\n                delta = chunk.choices[0].delta.content or \"\"\n                if delta:\n                    self.token_queue.put(delta)\n\n        except Exception as e:\n            self.token_queue.put(f\"\\n[Error: {e}]\")\n\n        finally:\n            self.token_queue.put(None)\n\n    def _poll_tokens(self):\n        try:\n            while True:\n                token = self.token_queue.get_nowait()\n\n                if token is None:\n                    self._finalize_assistant_message()\n                    break\n\n                self.current_assistant_buffer += token\n                self._append_to_last_chat(token)\n\n        except queue.Empty:\n            pass\n\n        self.root.after(20, self._poll_tokens)\n\n    def _finalize_assistant_message(self):\n        assistant_text = self.current_assistant_buffer\n        self.conversation.append({\"role\": \"assistant\", \"content\": assistant_text})\n\n        self.is_generating = False\n        self.input_box.configure(state=\"normal\")\n\n        # Replace the streaming label with parsed content\n        self._replace_with_parsed_message(assistant_text)\n\n    def _replace_with_parsed_message(self, text: str):\n        \"\"\"Parse the message and replace code blocks with interactive widgets.\"\"\"\n        if self.current_message_label:\n            self.current_message_label.destroy()\n            self.current_message_label = None\n\n        # Create a container for this message\n        message_container = ttk.Frame(self.chat_inner_frame)\n        message_container.pack(fill=\"x\", padx=5, pady=5)\n\n        # Add sender as copyable text\n        sender_text = tk.Text(\n            message_container,\n            height=1,\n            wrap=\"none\",\n            font=(\"TkDefaultFont\", 10, \"bold\"),\n            relief=\"flat\",\n            background=self.bg_color\n        )\n        sender_text.insert(\"1.0\", \"Assistant:\")\n        sender_text.configure(state=\"disabled\")\n        sender_text.pack(fill=\"x\")\n\n        # Split text by code blocks\n        parts = self._split_text_and_code(text)\n        \n        for part_type, content in parts:\n            if part_type == \"text\":\n                if content.strip():\n                    text_widget = tk.Text(\n                        message_container,\n                        height=content.count(\"\\n\") + 1 + int(len(content) * 0.012),\n                        wrap=\"word\",\n                        relief=\"flat\",\n                        background=self.bg_color\n                    )\n                    text_widget.insert(\"1.0\", content)\n                    text_widget.configure(state=\"disabled\")\n                    text_widget.pack(fill=\"x\", padx=5, pady=2)\n            elif part_type == \"code\":\n                proposal = CodeProposal(\n                    parent=message_container,\n                    code=content,\n                    on_replace=self._replace_code_panel,\n                    on_add=self._add_code_via_helper,\n                )\n                proposal.pack(fill=\"x\", pady=5)\n\n        # Scroll to bottom\n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n\n\n    def _split_text_and_code(self, text: str) -> list[tuple[str, str]]:\n        \"\"\"Split text into alternating text and code blocks.\"\"\"\n        parts = []\n        last_end = 0\n        \n        # Use non-overlapping findall to get all matches\n        for match in CODE_BLOCK_REGEX.finditer(text):\n            # Add text before code block\n            if match.start() > last_end:\n                parts.append((\"text\", text[last_end:match.start()]))\n            \n            # Add code block\n            parts.append((\"code\", match.group(1)))\n            last_end = match.end()\n            \n        # Add remaining text after last code block\n        if last_end < len(text):\n            parts.append((\"text\", text[last_end:]))\n            \n        return parts\n    \n    # -----------------------------\n    # Code Handling (Line-Number Based Approach)\n    # -----------------------------\n\n    def _add_line_numbers(self, code: str) -> str:\n        \"\"\"Prepend line numbers to each line of code.\"\"\"\n        lines = code.split(\"\\n\")\n        numbered_lines = [f\"{i+1} | {line}\" for i, line in enumerate(lines)]\n        return \"\\n\".join(numbered_lines)\n\n    def _add_code_via_helper(self, new_code: str):\n        \"\"\"Apply new code safely. If new_code contains top-level defs/classes, replace the existing block(s) instead of inserting.\"\"\"\n        if not self.code_contents.strip():\n            self._replace_code_panel(new_code)\n            return\n\n        blocks = self._extract_top_level_blocks(new_code)\n\n        # If the assistant gave us a full function/class, do a safe structural replace.\n        if blocks:\n            try:\n                updated = self.code_contents\n                for name, block_text in blocks:\n                    updated = self._replace_top_level_block_by_name(updated, name, block_text)\n\n                self._assert_no_duplicate_block_defs(updated, blocks)\n\n                self.code_contents = updated\n                self.code_panel.delete(\"1.0\", \"end\")\n                self.code_panel.insert(\"1.0\", updated)\n                self._append_chat(\"System\", \"Code updated successfully (structural replace)!\")\n                return\n            except Exception as e:\n                self._append_chat(\"System\", f\"Structural replace failed, falling back to helper insertion: {e}\")\n\n        # Fallback: original line-based helper insertion (good for small snippets that aren't whole defs/classes)\n        insertion_data = self._get_insertion_instructions(new_code)\n\n        if not insertion_data:\n            self._append_chat(\"System\", \"Helper model did not return valid instructions.\")\n            return\n\n        try:\n            updated_code = self._apply_line_based_edit(\n                insertion_data[\"insertion_point\"],\n                insertion_data[\"delete_lines\"],\n                new_code,\n                insertion_data[\"indent_spaces\"]\n            )\n            self.code_contents = updated_code\n            self.code_panel.delete(\"1.0\", \"end\")\n            self.code_panel.insert(\"1.0\", updated_code)\n            self._append_chat(\"System\", \"Code updated successfully!\")\n        except Exception as e:\n            self._append_chat(\"System\", f\"Edit failed: {e}\")\n\n\n    def _extract_top_level_blocks(self, code: str) -> list[tuple[str, str]]:\n        \"\"\"\n        Return list of (name, block_text) for top-level `def name(...):` and `class Name...:`.\n        Only matches blocks that start at column 0.\n        \"\"\"\n        lines = code.splitlines(True)  # keep line endings\n        starts = []\n        for i, line in enumerate(lines):\n            m = re.match(r'^(def|class)\\s+([A-Za-z_][A-Za-z0-9_]*)\\b.*:\\s*(#.*)?\\n?$', line)\n            if m:\n                starts.append((i, m.group(2)))\n\n        blocks: list[tuple[str, str]] = []\n        for idx, (start_i, name) in enumerate(starts):\n            end_i = starts[idx + 1][0] if idx + 1 < len(starts) else len(lines)\n            block_text = \"\".join(lines[start_i:end_i]).rstrip(\"\\n\")\n            blocks.append((name, block_text))\n        return blocks\n\n\n    def _replace_top_level_block_by_name(self, original: str, name: str, new_block: str) -> str:\n        \"\"\"\n        Replace the first top-level `def name` or `class name` block in original with new_block.\n        A block is from its `def/class` line at column 0 up to (but not including) the next top-level def/class line.\n        \"\"\"\n        lines = original.splitlines(True)  # keep line endings\n\n        # Find block start\n        start_i = None\n        for i, line in enumerate(lines):\n            if re.match(rf'^(def|class)\\s+{re.escape(name)}\\b.*:\\s*(#.*)?\\n?$', line):\n                start_i = i\n                break\n\n        if start_i is None:\n            raise ValueError(f\"Could not find existing top-level def/class named '{name}' to replace.\")\n\n        # Find block end\n        end_i = len(lines)\n        for j in range(start_i + 1, len(lines)):\n            if re.match(r'^(def|class)\\s+[A-Za-z_][A-Za-z0-9_]*\\b.*:\\s*(#.*)?\\n?$', lines[j]):\n                end_i = j\n                break\n\n        # Preserve a single trailing newline style around the replacement\n        replacement = new_block.rstrip(\"\\n\") + \"\\n\"\n        new_lines = lines[:start_i] + [replacement] + lines[end_i:]\n        return \"\".join(new_lines)\n\n\n    def _assert_no_duplicate_block_defs(self, updated: str, replaced_blocks: list[tuple[str, str]]) -> None:\n        \"\"\"\n        Ensure we didn't create duplicate top-level defs/classes for any replaced name.\n        \"\"\"\n        for name, _block in replaced_blocks:\n            occurrences = len(re.findall(rf'^(def|class)\\s+{re.escape(name)}\\b', updated, flags=re.MULTILINE))\n            if occurrences != 1:\n                raise ValueError(f\"After edit, expected exactly 1 top-level definition for '{name}', found {occurrences}.\")\n\n\n    def _get_insertion_instructions(self, new_code: str) -> dict | None:\n        \"\"\"Ask helper model for insertion point and lines to delete using line numbers, with verification.\"\"\"\n        # Add line numbers to current code\n        numbered_code = self._add_line_numbers(self.code_contents)\n        \n        system_prompt = (\n            \"You are a code editing assistant. Your job is to determine where to insert new code \"\n            \"and which lines (if any) to delete from the existing code.\\n\\n\"\n            \"You will receive:\\n\"\n            \"1. The current code with line numbers (format: '1 | code here')\\n\"\n            \"2. New code to insert\\n\\n\"\n            \"You must respond ONLY with JSON in this exact format:\\n\"\n            \"{\\n\"\n            '  \"insertion_point\": <line_number>,\\n'\n            '  \"delete_lines\": [<line_numbers>],\\n'\n            '  \"indent_spaces\": <number_of_spaces>\\n'\n            \"}\\n\\n\"\n            \"Rules:\\n\"\n            \"- insertion_point: The line number AFTER which to insert the new code (use 0 to insert at the beginning)\\n\"\n            \"- delete_lines: Array of line numbers to delete (can be empty [] if just inserting)\\n\"\n            \"- indent_spaces: Number of spaces to add to the beginning of each line of inserted code (to match surrounding indentation)\\n\"\n            \"- Use the CURRENT line numbers you see - don't worry about how insertion affects numbering\\n\"\n            \"- If replacing code, include those line numbers in delete_lines\\n\"\n            \"- If just inserting, leave delete_lines empty\\n\"\n            \"- Look at the indentation of surrounding code to determine indent_spaces\\n\\n\"\n            \"Example 1 - Replace lines 5-7 with 8 spaces of indentation:\\n\"\n            '{\"insertion_point\": 4, \"delete_lines\": [5, 6, 7], \"indent_spaces\": 8}\\n\\n'\n            \"Example 2 - Insert after line 10 with 4 spaces:\\n\"\n            '{\"insertion_point\": 10, \"delete_lines\": [], \"indent_spaces\": 4}\\n\\n'\n            \"Example 3 - Insert at beginning with no indentation:\\n\"\n            '{\"insertion_point\": 0, \"delete_lines\": [], \"indent_spaces\": 0}\\n\\n'\n            \"Respond with ONLY the JSON, no explanations.\"\n        )\n\n        user_prompt = (\n            \"CURRENT CODE (with line numbers):\\n\"\n            f\"{numbered_code}\\n\\n\"\n            \"NEW CODE TO INSERT:\\n\"\n            f\"{new_code}\\n\"\n        )\n\n        model = self.helper_model.get()\n        client = self._get_client_for_model(model)\n        max_tokens = self._get_max_tokens_for_model(model)\n        \n        # First attempt\n        conversation = [\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ]\n        \n        data = self._call_helper_and_parse(client, model, max_tokens, conversation)\n        \n        if not data:\n            return None\n        \n        print(\"First attempt JSON:\", data)\n        \n        # Apply the edit and show result to model for verification\n        try:\n            updated_code = self._apply_line_based_edit(\n                data[\"insertion_point\"],\n                data[\"delete_lines\"],\n                new_code,\n                data[\"indent_spaces\"]\n            )\n            \n            # Show the result to the model for verification\n            numbered_result = self._add_line_numbers(updated_code)\n            \n            verification_prompt = (\n                \"Here is the result of applying your edit instructions:\\n\\n\"\n                f\"{numbered_result}\\n\\n\"\n                \"Does this look correct? Did the new code get inserted in the right place with proper indentation?\\n\"\n                \"If YES, respond with just: CORRECT\\n\"\n                \"If NO, provide a corrected JSON with the right insertion_point, delete_lines, and indent_spaces.\\n\"\n                \"Remember the original code had these line numbers:\\n\"\n                f\"{numbered_code}\\n\"\n            )\n            \n            conversation.append({\"role\": \"assistant\", \"content\": json.dumps(data)})\n            conversation.append({\"role\": \"user\", \"content\": verification_prompt})\n            \n            params = {\n                \"model\": model,\n                \"messages\": conversation,\n            }\n            \n            if self._uses_max_completion_tokens(model):\n                params[\"max_completion_tokens\"] = max_tokens\n            else:\n                params[\"max_tokens\"] = max_tokens\n            \n            verification_response = client.chat.completions.create(**params)\n            verification_text = verification_response.choices[0].message.content or \"\"\n            \n            print(\"Verification response:\", verification_text)\n            \n            # Check if model says it's correct\n            if \"CORRECT\" in verification_text.upper():\n                print(\"Model verified the edit is correct\")\n                return data\n            \n            # Try to extract corrected JSON\n            corrected_data = self._extract_json_from_text(verification_text)\n            \n            if corrected_data and self._validate_json_format(corrected_data):\n                print(\"Second attempt JSON:\", corrected_data)\n                return corrected_data\n            \n            # If no valid correction, return original\n            print(\"No valid correction provided, using original\")\n            return data\n            \n        except Exception as e:\n            print(f\"Error during verification: {e}\")\n            return data\n\n    def _call_helper_and_parse(self, client, model: str, max_tokens: int, conversation: list) -> dict | None:\n        \"\"\"Call the helper model and parse JSON response.\"\"\"\n        params = {\n            \"model\": model,\n            \"messages\": conversation,\n        }\n        \n        if self._uses_max_completion_tokens(model):\n            params[\"max_completion_tokens\"] = max_tokens\n        else:\n            params[\"max_tokens\"] = max_tokens\n        \n        try:\n            response = client.chat.completions.create(**params)\n            response_text = response.choices[0].message.content or \"\"\n            \n            print(\"Helper response:\", response_text)\n            \n            return self._extract_json_from_text(response_text)\n            \n        except Exception as e:\n            print(f\"Error calling helper: {e}\")\n            return None\n    \n    def _extract_json_from_text(self, text: str) -> dict | None:\n        \"\"\"Extract and parse JSON from text that may contain markdown or other content.\"\"\"\n        # Try to find JSON in the text\n        json_match = re.search(r'\\{[^}]+\\}', text, re.DOTALL)\n        if json_match:\n            text = json_match.group(0)\n        \n        try:\n            data = json.loads(text)\n            if self._validate_json_format(data):\n                return data\n        except:\n            pass\n        \n        return None\n    \n    def _validate_json_format(self, data: dict) -> bool:\n        \"\"\"Validate that JSON has required fields with correct types.\"\"\"\n        if \"insertion_point\" not in data or \"delete_lines\" not in data or \"indent_spaces\" not in data:\n            return False\n        \n        if not isinstance(data[\"insertion_point\"], int):\n            return False\n        \n        if not isinstance(data[\"delete_lines\"], list):\n            return False\n        \n        if not isinstance(data[\"indent_spaces\"], int):\n            return False\n        \n        return True\n\n    def _apply_line_based_edit(self, insertion_point: int, delete_lines: list, new_code: str, indent_spaces: int) -> str:\n        \"\"\"Apply insertion and deletion based on line numbers, with indentation.\"\"\"\n        lines = self.code_contents.split(\"\\n\")\n        \n        # Validate line numbers\n        if insertion_point < 0 or insertion_point > len(lines):\n            raise ValueError(f\"Invalid insertion point: {insertion_point}\")\n        \n        for line_num in delete_lines:\n            if line_num < 1 or line_num > len(lines):\n                raise ValueError(f\"Invalid line number to delete: {line_num}\")\n        \n        # Convert delete_lines to 0-indexed and sort in reverse order\n        delete_indices = sorted([line_num - 1 for line_num in delete_lines], reverse=True)\n        \n        # Adjust insertion point if we're deleting lines before it\n        adjusted_insertion = insertion_point\n        for idx in delete_indices:\n            if idx < insertion_point:\n                adjusted_insertion -= 1\n        \n        # Delete lines (in reverse order to preserve indices)\n        for idx in delete_indices:\n            del lines[idx]\n        \n        # Apply indentation to new code\n        indent = \" \" * indent_spaces\n        new_lines = new_code.split(\"\\n\")\n        indented_lines = [indent + line for line in new_lines]\n        \n        # Insert new code at the adjusted position\n        lines[adjusted_insertion:adjusted_insertion] = indented_lines\n        \n        return \"\\n\".join(lines)\n\n    def _replace_code_panel(self, code: str):\n        self.code_contents = code\n        self.code_panel.delete(\"1.0\", \"end\")\n        self.code_panel.insert(\"1.0\", code)\n\n    # -----------------------------\n    # Persistence\n    # -----------------------------\n    def save_conversation(self, path: str | None = None):\n        if path is None:\n            path = filedialog.asksaveasfilename(\n                defaultextension=\".json\",\n                filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")]\n            )\n            if not path:\n                return\n        try:\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(self.conversation, f, indent=2, ensure_ascii=False)\n            self.auto_save_path = path\n            messagebox.showinfo(\"Saved\", f\"Conversation saved to\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Save error\", str(e))\n\n    def load_conversation(self):\n        path = filedialog.askopenfilename(\n            defaultextension=\".json\",\n            filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")]\n        )\n        if not path:\n            return\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                loaded = json.load(f)\n            if not isinstance(loaded, list):\n                raise ValueError(\"File must contain a list of messages.\")\n            self.conversation = loaded\n            self.auto_save_path = path\n            self._redraw_chat()\n            messagebox.showinfo(\"Loaded\", f\"Conversation loaded from\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Load error\", str(e))\n\n    def export_markdown(self):\n        path = filedialog.asksaveasfilename(\n            defaultextension=\".md\",\n            filetypes=[(\"Markdown files\", \"*.md\"), (\"All files\", \"*.*\")]\n        )\n        if not path:\n            return\n        try:\n            lines = []\n            for msg in self.conversation:\n                role = msg.get(\"role\", \"\")\n                content = msg.get(\"content\", \"\")\n                if role == \"system\":\n                    continue\n                name = \"You\" if role == \"user\" else \"Assistant\"\n                lines.append(f\"**{name}:**\\n{content}\\n\")\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"\\n\".join(lines))\n            messagebox.showinfo(\"Exported\", f\"Markdown exported to\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Export error\", str(e))\n\n    def _redraw_chat(self):\n        for w in self.chat_inner_frame.winfo_children():\n            w.destroy()\n        self.current_message_label = None\n        for msg in self.conversation:\n            role = msg.get(\"role\")\n            content = msg.get(\"content\", \"\")\n            if role == \"system\":\n                continue\n            sender = \"You\" if role == \"user\" else \"Assistant\"\n            if role == \"assistant\":\n                self._replace_with_parsed_message(content)\n            else:\n                self._append_chat(sender, content)\n\n    # -----------------------------\n    # UI Helpers\n    # -----------------------------\n\n    def _create_message_frame(self, sender: str, text: str):\n        container = ttk.Frame(self.chat_inner_frame)\n        container.pack(fill=\"x\", padx=10, pady=5)\n        \n        header = tk.Label(container, text=f\"{sender}:\", font=(\"TkDefaultFont\", 10, \"bold\"),\n                         bg=self.bg_color)\n        header.pack(fill=\"x\")\n        \n        # Dynamic height for content\n        line_count = text.count(\"\\n\") + 1\n        body = tk.Label(container, text=text, wraplength=800,\n                      justify=\"left\", bg=self.bg_color)\n        body.pack(fill=\"x\", padx=5)\n        \n        return body, container\n    \n    def _append_chat(self, sender: str, text: str):\n        \"\"\"Modified for tighter user message spacing.\"\"\"\n        body, container = self._create_message_frame(sender, text)\n        \n        if sender == \"Assistant\":\n            self.current_message_label = body\n            self.current_message_container = container\n        \n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n    \n    def _replace_with_parsed_message(self, text: str):\n        \"\"\"Parse the message and replace code blocks with interactive widgets.\"\"\"\n        if self.current_message_label:\n            self.current_message_label.destroy()\n            self.current_message_label = None\n    \n        # Create a container for this message\n        message_container = ttk.Frame(self.chat_inner_frame)\n        message_container.pack(fill=\"x\", padx=5, pady=5)\n    \n        # Add sender as copyable text\n        sender_text = tk.Text(\n            message_container,\n            height=1,\n            wrap=\"none\",\n            font=(\"TkDefaultFont\", 10, \"bold\"),\n            relief=\"flat\",\n            background=self.bg_color\n        )\n        sender_text.insert(\"1.0\", \"Assistant:\")\n        sender_text.configure(state=\"disabled\")\n        sender_text.pack(fill=\"x\")\n    \n        # Split text by code blocks\n        parts = self._split_text_and_code(text)\n        \n        for part_type, content in parts:\n            if part_type == \"text\":\n                if content.strip():\n                    body, _ = self._create_message_frame(\"Assistant\", content)\n            elif part_type == \"code\":\n                proposal = CodeProposal(\n                    parent=message_container,\n                    code=content,\n                    on_replace=self._replace_code_panel,\n                    on_add=self._add_code_via_helper,\n                )\n                proposal.pack(fill=\"x\", pady=5)\n    \n        # Scroll to bottom\n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n    "
  },
  {
    "role": "assistant",
    "content": "Here are the changes you should make to **fully de-duplicate and refactor your message display logic** to reduce repetition:\n\n---\n\n### 1. Refactor: Make `_create_message_frame` more flexible\n\n- Take a `parent` argument so it can be used for both chat canvas and parsed code blocks.\n- Add parameters for `sender`, `text`, and `padx` so it handles both regular and code-messages.\n- Support passing in a font arg if needed for customization.\n\n**Replace your current `_create_message_frame` function with:**\n\n```python\ndef _create_message_frame(self, parent, sender: str, text: str, padx=10, pady=5, font=None):\n    container = ttk.Frame(parent)\n    container.pack(fill=\"x\", padx=padx, pady=pady)\n\n    header = tk.Label(\n        container,\n        text=f\"{sender}:\",\n        font=font or (\"TkDefaultFont\", 10, \"bold\"),\n        bg=self.bg_color\n    )\n    header.pack(fill=\"x\")\n\n    line_count = text.count(\"\\n\") + 1\n    body = tk.Label(\n        container,\n        text=text,\n        wraplength=800,\n        justify=\"left\",\n        bg=self.bg_color\n    )\n    body.pack(fill=\"x\", padx=5)\n\n    return body, container\n```\n---\n\n### 2. Use `_create_message_frame` in both `_append_chat` and `_replace_with_parsed_message`\n\n#### Replace the `_append_chat` method with:\n\n```python\ndef _append_chat(self, sender: str, text: str):\n    body, container = self._create_message_frame(self.chat_inner_frame, sender, text)\n    if sender == \"Assistant\":\n        self.current_message_label = body\n        self.current_message_container = container\n    self.chat_canvas.update_idletasks()\n    self.chat_canvas.yview_moveto(1.0)\n```\n\n#### Update `_replace_with_parsed_message` to use `_create_message_frame` for non-code blocks:\n\n**Replace all manual tk.Text construction of chat text in `_replace_with_parsed_message` with this:**\n\n```python\ndef _replace_with_parsed_message(self, text: str):\n    if self.current_message_label:\n        self.current_message_label.destroy()\n        self.current_message_label = None\n\n    message_container = ttk.Frame(self.chat_inner_frame)\n    message_container.pack(fill=\"x\", padx=5, pady=5)\n\n    # Always add the sender label first (and make it selectable/copyable if you want)\n    sender_label = tk.Label(\n        message_container,\n        text=\"Assistant:\",\n        font=(\"TkDefaultFont\", 10, \"bold\"),\n        bg=self.bg_color\n    )\n    sender_label.pack(fill=\"x\")\n\n    parts = self._split_text_and_code(text)\n    for part_type, content in parts:\n        if part_type == \"text\" and content.strip():\n            # Create a reused message frame for each text part\n            self._create_message_frame(\n                message_container,\n                sender=\"\",\n                text=content,\n                padx=5,\n                pady=2,\n                font=(\"TkDefaultFont\", 10, \"normal\")\n            )\n        elif part_type == \"code\":\n            proposal = CodeProposal(\n                parent=message_container,\n                code=content,\n                on_replace=self._replace_code_panel,\n                on_add=self._add_code_via_helper,\n            )\n            proposal.pack(fill=\"x\", pady=5)\n\n    self.chat_canvas.update_idletasks()\n    self.chat_canvas.yview_moveto(1.0)\n```\n\n---\n\n### 3. Remove the now-unnecessary duplicate text-widget logic from `_replace_with_parsed_message`\n\nDelete the chunk:\n```python\nif part_type == \"text\":\n    if content.strip():\n        text_widget = tk.Text(\n            message_container,\n            height=content.count(\"\\n\") + 1 + int(len(content) * 0.012),\n            wrap=\"word\",\n            relief=\"flat\",\n            background=self.bg_color\n        )\n        text_widget.insert(\"1.0\", content)\n        text_widget.configure(state=\"disabled\")\n        text_widget.pack(fill=\"x\", padx=5, pady=2)\n```\nwhich is now replaced by the `_create_message_frame(...)` call above.\n\n---\n\n## Summary\n\n**You should:**\n- Refactor `_create_message_frame` to accept a parent widget and parameters for content formatting.\n- Use it in both `_append_chat` (parent is `self.chat_inner_frame`) and in `_replace_with_parsed_message` (parent is the new message container).\n- In `_replace_with_parsed_message`, do **not** manually create a new tk.Text widget for text blocks; reuse `_create_message_frame` for all non-code message content.\n\n---\n\n**These changes will make your code DRY, easier to maintain, and improve UI consistency.**"
  }
]