[
  {
    "role": "system",
    "content": "You are a helpful coding assistant."
  },
  {
    "role": "user",
    "content": "Propose 1 change to your UI's code."
  },
  {
    "role": "user",
    "content": "Here's my current code:\n```import os\nimport re\nimport threading\nimport queue\nimport tkinter as tk\nfrom tkinter import ttk, filedialog, messagebox\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nimport json\n\n# -----------------------------\n# Environment / Client Setup\n# -----------------------------\n\nload_dotenv()\n\ngroq_client = OpenAI(\n    api_key=os.getenv(\"GROQ_API_KEY\"),\n    base_url=\"https://api.groq.com/openai/v1\",\n)\n\nopenai_client = OpenAI(\n    api_key=os.getenv(\"OPENAI_API_KEY\"),\n)\n\n# Model configurations\nGROQ_MODELS = [\n    \"llama-3.3-70b-versatile\",\n    \"moonshotai/kimi-k2-instruct\",\n    \"moonshotai/kimi-k2-instruct-0905\",\n    \"openai/gpt-oss-120b\",\n    \"openai/gpt-oss-20b\",\n    \"meta-llama/llama-4-maverick-17b-128e-instruct\",\n]\n\nOPENAI_MODELS = [\n    \"gpt-5.2\",\n    \"gpt-5-mini\",\n    \"gpt-4.1\",\n]\n\nALL_MODELS = GROQ_MODELS + OPENAI_MODELS\n\nCODE_BLOCK_REGEX = re.compile(\n    r\"```(?:\\w+)?\\s*(.*?)```\",\n    re.DOTALL\n)\n\n# -----------------------------\n# UI\n# -----------------------------\nclass CodeProposal(ttk.Frame):\n    def __init__(self, parent, code: str, on_replace, on_add):\n        super().__init__(parent)\n        self.code = code\n\n        # Calculate height: number of lines + 1\n        line_count = code.count(\"\\n\") + 1\n        \n        self.text = tk.Text(\n            self,\n            height=line_count,\n            wrap=\"none\",\n            font=(\"Courier New\", 10),\n            padx=5,\n            pady=5,\n            highlightthickness=1 # Border for code blocks\n        )\n        self.text.insert(\"1.0\", code)\n        self.text.configure(state=\"disabled\")\n        self.text.pack(fill=\"x\", padx=5, pady=(5, 2))\n\n        button_row = ttk.Frame(self)\n        button_row.pack(anchor=\"e\", padx=5, pady=(0, 5))\n\n        ttk.Button(button_row, text=\"Replace\", command=lambda: on_replace(code)).pack(side=\"right\", padx=2)\n        ttk.Button(button_row, text=\"Add\", command=lambda: on_add(code)).pack(side=\"right\", padx=2)\n\nclass ChatUI:\n    def __init__(self, root: tk.Tk):\n        self.root = root\n        self.root.title(\"Chat + Code UI\")\n        self.root.geometry(\"1100x650\")\n\n        self.conversation = [\n            {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"}\n        ]\n\n        self.token_queue = queue.Queue()\n        self.is_generating = False\n        self.current_assistant_buffer = \"\"\n\n        self.code_contents = \"\"\n\n        # ---- persistence helpers ----\n        self.auto_save_path: str | None = None\n        self.auto_save_after_id: str | None = None\n        self.auto_save_interval_ms = 30_000\n        \n        # Default models\n        self.chat_model = tk.StringVar(value=\"llama-3.3-70b-versatile\")\n        self.helper_model = tk.StringVar(value=\"llama-3.3-70b-versatile\")\n        \n        # Temperature controls\n        self.chat_temp = tk.DoubleVar(value=0.7)\n        self.helper_temp = tk.DoubleVar(value=0.3)\n\n        self._build_layout()\n        self._bind_keys()\n        self._poll_tokens()\n\n    # -----------------------------\n    # Layout\n    # -----------------------------\n    def _select_all_code(self, event=None):\n        self.code_panel.tag_add(\"sel\", \"1.0\", \"end\")\n\n    def _build_layout(self) -> None:\n        self.root.rowconfigure(0, weight=0)\n        self.root.rowconfigure(1, weight=1)\n        self.root.rowconfigure(2, weight=0)\n        self.root.columnconfigure(0, weight=1)\n\n        \n        # ----------------------\n        # Model Selection Bar\n        # ----------------------\n        model_frame = ttk.Frame(self.root)\n        model_frame.grid(row=0, column=0, sticky=\"ew\", padx=5, pady=5)\n\n        # ---------- Chat model column ----------\n        chat_col = ttk.Frame(model_frame)\n        chat_col.pack(side=\"left\", padx=(0, 30))\n\n        ttk.Label(chat_col, text=\"Chat Model:\").pack(anchor=\"w\")\n        chat_dropdown = ttk.Combobox(\n            chat_col,\n            textvariable=self.chat_model,\n            values=ALL_MODELS,\n            state=\"readonly\",\n            width=40\n        )\n        chat_dropdown.pack(anchor=\"w\")\n\n        chat_temp_frame = ttk.Frame(chat_col)\n        chat_temp_frame.pack(anchor=\"w\", pady=(5, 0))\n        ttk.Label(chat_temp_frame, text=\"Temp:\").pack(side=\"left\")\n        chat_temp_scale = ttk.Scale(\n            chat_temp_frame,\n            from_=0.0,\n            to=1.0,\n            variable=self.chat_temp,\n            orient=\"horizontal\",\n            length=100\n        )\n        chat_temp_scale.pack(side=\"left\", padx=(5, 0))\n        self.chat_temp_label = ttk.Label(chat_temp_frame, textvariable=self.chat_temp)\n        self.chat_temp_label.pack(side=\"left\", padx=(5, 0))\n\n        # ---------- Helper model column ----------\n        helper_col = ttk.Frame(model_frame)\n        helper_col.pack(side=\"left\")\n\n        ttk.Label(helper_col, text=\"Helper Model:\").pack(anchor=\"w\")\n        helper_dropdown = ttk.Combobox(\n            helper_col,\n            textvariable=self.helper_model,\n            values=ALL_MODELS,\n            state=\"readonly\",\n            width=40\n        )\n        helper_dropdown.pack(anchor=\"w\")\n\n        helper_temp_frame = ttk.Frame(helper_col)\n        helper_temp_frame.pack(anchor=\"w\", pady=(5, 0))\n        ttk.Label(helper_temp_frame, text=\"Temp:\").pack(side=\"left\")\n        helper_temp_scale = ttk.Scale(\n            helper_temp_frame,\n            from_=0.0,\n            to=1.0,\n            variable=self.helper_temp,\n            orient=\"horizontal\",\n            length=100\n        )\n        helper_temp_scale.pack(side=\"left\", padx=(5, 0))\n        self.helper_temp_label = ttk.Label(helper_temp_frame, textvariable=self.helper_temp)\n        self.helper_temp_label.pack(side=\"left\", padx=(5, 0))\n        \n\n        # ----------------------\n        # Menu bar\n        # ----------------------\n        menubar = tk.Menu(self.root)\n        file_menu = tk.Menu(menubar, tearoff=0)\n        file_menu.add_command(label=\"Save conversation…\", command=self.save_conversation)\n        file_menu.add_command(label=\"Load conversation…\", command=self.load_conversation)\n        file_menu.add_separator()\n        menubar.add_cascade(label=\"File\", menu=file_menu)\n        self.root.config(menu=menubar)\n\n        main_pane = ttk.PanedWindow(self.root, orient=\"horizontal\")\n        main_pane.grid(row=1, column=0, sticky=\"nsew\")\n\n        # ----------------------\n        # Chat + Code Proposals\n        # ----------------------\n        chat_frame = ttk.Frame(main_pane)\n        chat_frame.rowconfigure(0, weight=1)\n        chat_frame.columnconfigure(0, weight=1)\n\n        # Scrollable canvas\n        self.chat_canvas = tk.Canvas(chat_frame)\n        self.chat_scrollbar = ttk.Scrollbar(chat_frame, command=self.chat_canvas.yview)\n        self.chat_canvas.configure(yscrollcommand=self.chat_scrollbar.set)\n\n        self.chat_scrollbar.grid(row=0, column=1, sticky=\"ns\")\n        self.chat_canvas.grid(row=0, column=0, sticky=\"nsew\")\n\n        # Inner frame to hold all messages\n        self.chat_inner_frame = ttk.Frame(self.chat_canvas)\n        self.chat_canvas.create_window((0, 0), window=self.chat_inner_frame, anchor=\"nw\")\n\n        # Update scroll region when content changes\n        self.chat_inner_frame.bind(\n            \"<Configure>\",\n            lambda e: self.chat_canvas.configure(scrollregion=self.chat_canvas.bbox(\"all\"))\n        )\n\n        # Track the current message label for streaming\n        self.current_message_label = None\n        \n        # Get background color from a standard widget\n        self.bg_color = self.root.cget(\"background\")\n\n        # ----------------------\n        # Code Panel\n        # ----------------------\n        code_frame = ttk.Frame(main_pane)\n        code_frame.rowconfigure(0, weight=1)\n        code_frame.columnconfigure(0, weight=1)\n\n        self.code_panel = tk.Text(code_frame, wrap=\"none\")\n        self.code_panel.grid(row=0, column=0, sticky=\"nsew\")\n        \n        # Bind to sync code_contents when user edits\n        self.code_panel.bind(\"<<Modified>>\", self._on_code_modified)\n\n        # Add this line to bind Ctrl+A to select all code\n        self.code_panel.bind_all(\"<Control-a>\", self._select_all_code)\n        \n        \n\n        code_scroll = ttk.Scrollbar(code_frame, command=self.code_panel.yview)\n        code_scroll.grid(row=0, column=1, sticky=\"ns\")\n        self.code_panel[\"yscrollcommand\"] = code_scroll.set\n\n        main_pane.add(chat_frame)\n        main_pane.add(code_frame)\n\n        # ----------------------\n        # Input Box\n        # ----------------------\n        self.input_box = tk.Text(self.root, height=5, wrap=\"word\")\n        self.input_box.grid(row=2, column=0, sticky=\"nsew\")\n\n        self.root.update_idletasks()\n        main_pane.sashpos(0, int(self.root.winfo_width() * 0.70))\n    \n    def _get_client_for_model(self, model: str):\n        \"\"\"Return the appropriate client for the given model.\"\"\"\n        if model in OPENAI_MODELS:\n            return openai_client\n        else:\n            return groq_client\n    \n    def _get_max_tokens_for_model(self, model: str):\n        \"\"\"Return appropriate max_tokens for the given model.\"\"\"\n        if model in OPENAI_MODELS:\n            return 16000\n        else:\n            return 8000\n    \n    def _uses_max_completion_tokens(self, model: str):\n        \"\"\"Check if model uses max_completion_tokens instead of max_tokens.\"\"\"\n        return model in [\"gpt-5.2\", \"gpt-5-mini\"]\n\n    def _bind_keys(self):\n        self.input_box.bind(\"<Return>\", self._on_enter)\n        self.input_box.bind(\"<Shift-Return>\", lambda e: None)\n    \n    def _on_code_modified(self, event):\n        \"\"\"Sync code_contents when user edits the code panel.\"\"\"\n        if self.code_panel.edit_modified():\n            self.code_contents = self.code_panel.get(\"1.0\", \"end-1c\")\n            self.code_panel.edit_modified(False)\n\n    # -----------------------------\n    # Input\n    # -----------------------------\n\n    def _on_enter(self, event):\n        if self.is_generating:\n            return \"break\"\n\n        text = self.input_box.get(\"1.0\", \"end-1c\").strip()\n        if not text:\n            return \"break\"\n\n        self.input_box.delete(\"1.0\", \"end\")\n        self._append_chat(\"You\", text)\n        \n        # Add user message to conversation\n        self.conversation.append({\"role\": \"user\", \"content\": text})\n        \n        # Add invisible context about current code if it exists\n        if self.code_contents.strip():\n            self.conversation.append({\n                \"role\": \"user\",\n                \"content\": f\"Here's my current code:\\n```{self.code_contents}```\\n Here are my rules: **Never use ellipses or any placeholder text—inside or outside comments—to indicate omitted code; always supply the complete, runnable snippet.** Avoid rewriting entire files unless specifically asked.\"\n            })\n\n        self._start_generation()\n        return \"break\"\n\n    # -----------------------------\n    # Chat Generation\n    # -----------------------------\n\n    def _start_generation(self):\n        self.is_generating = True\n        self.input_box.configure(state=\"disabled\")\n        self.current_assistant_buffer = \"\"\n\n        threading.Thread(\n            target=self._stream_chat_response, daemon=True\n        ).start()\n\n    def _stream_chat_response(self):\n        try:\n            model = self.chat_model.get()\n            client = self._get_client_for_model(model)\n            max_tokens = self._get_max_tokens_for_model(model)\n            \n            # Build request parameters\n            params = {\n                \"model\": model,\n                \"messages\": self.conversation,\n                \"stream\": True,\n                \"temperature\": self.chat_temp.get(),\n            }\n            \n            # Use max_completion_tokens for GPT-5.2 and GPT-5-mini\n            if self._uses_max_completion_tokens(model):\n                params[\"max_completion_tokens\"] = max_tokens\n            else:\n                params[\"max_tokens\"] = max_tokens\n            \n            stream = client.chat.completions.create(**params)\n\n            for chunk in stream:\n                delta = chunk.choices[0].delta.content or \"\"\n                if delta:\n                    self.token_queue.put(delta)\n\n        except Exception as e:\n            self.token_queue.put(f\"\\n[Error: {e}]\")\n\n        finally:\n            self.token_queue.put(None)\n\n    def _poll_tokens(self):\n        try:\n            while True:\n                token = self.token_queue.get_nowait()\n\n                if token is None:\n                    self._finalize_assistant_message()\n                    break\n\n                self.current_assistant_buffer += token\n                self._append_to_last_chat(token)\n\n        except queue.Empty:\n            pass\n\n        self.root.after(20, self._poll_tokens)\n\n    def _finalize_assistant_message(self):\n        assistant_text = self.current_assistant_buffer\n        self.conversation.append({\"role\": \"assistant\", \"content\": assistant_text})\n\n        self.is_generating = False\n        self.input_box.configure(state=\"normal\")\n\n        # Replace the streaming label with parsed content\n        self._replace_with_parsed_message(assistant_text)\n\n    def _replace_with_parsed_message(self, text: str):\n        \"\"\"Parse the message and replace code blocks with interactive widgets.\"\"\"\n        if self.current_message_label:\n            self.current_message_label.destroy()\n            self.current_message_label = None\n\n        # Create a container for this message\n        message_container = ttk.Frame(self.chat_inner_frame)\n        message_container.pack(fill=\"x\", padx=5, pady=5)\n\n        # Add sender as copyable text\n        sender_text = tk.Text(\n            message_container,\n            height=1,\n            wrap=\"none\",\n            font=(\"TkDefaultFont\", 10, \"bold\"),\n            relief=\"flat\",\n            background=self.bg_color\n        )\n        sender_text.insert(\"1.0\", \"Assistant:\")\n        sender_text.configure(state=\"disabled\")\n        sender_text.pack(fill=\"x\")\n\n        # Split text by code blocks\n        parts = self._split_text_and_code(text)\n        \n        for part_type, content in parts:\n            if part_type == \"text\":\n                if content.strip():\n                    text_widget = tk.Text(\n                        message_container,\n                        height=content.count(\"\\n\") + 1 + int(len(content) * 0.012),\n                        wrap=\"word\",\n                        relief=\"flat\",\n                        background=self.bg_color\n                    )\n                    text_widget.insert(\"1.0\", content)\n                    text_widget.configure(state=\"disabled\")\n                    text_widget.pack(fill=\"x\", padx=5, pady=2)\n            elif part_type == \"code\":\n                proposal = CodeProposal(\n                    parent=message_container,\n                    code=content,\n                    on_replace=self._replace_code_panel,\n                    on_add=self._add_code_via_helper,\n                )\n                proposal.pack(fill=\"x\", pady=5)\n\n        # Scroll to bottom\n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n\n    def _split_text_and_code(self, text: str):\n        \"\"\"Split text into alternating text and code blocks.\"\"\"\n        parts = []\n        last_end = 0\n        \n        for match in CODE_BLOCK_REGEX.finditer(text):\n            # Add text before code block\n            if match.start() > last_end:\n                parts.append((\"text\", text[last_end:match.start()]))\n            \n            # Add code block\n            parts.append((\"code\", match.group(1)))\n            last_end = match.end()\n        \n        # Add remaining text after last code block\n        if last_end < len(text):\n            parts.append((\"text\", text[last_end:]))\n        \n        return parts\n\n    # -----------------------------\n    # Code Handling (Line-Number Based Approach)\n    # -----------------------------\n\n    def _add_line_numbers(self, code: str) -> str:\n        \"\"\"Prepend line numbers to each line of code.\"\"\"\n        lines = code.split(\"\\n\")\n        numbered_lines = [f\"{i+1} | {line}\" for i, line in enumerate(lines)]\n        return \"\\n\".join(numbered_lines)\n\n    def _add_code_via_helper(self, new_code: str):\n        \"\"\"Ask helper model for insertion point and lines to delete, then apply.\"\"\"\n        if not self.code_contents.strip():\n            self._replace_code_panel(new_code)\n            return\n\n        # Get insertion instructions from helper model\n        insertion_data = self._get_insertion_instructions(new_code)\n        \n        if not insertion_data:\n            self._append_chat(\"System\", \"Helper model did not return valid instructions.\")\n            return\n\n        # Try to apply the insertion and deletion\n        try:\n            updated_code = self._apply_line_based_edit(\n                insertion_data[\"insertion_point\"],\n                insertion_data[\"delete_lines\"],\n                new_code,\n                insertion_data[\"indent_spaces\"]\n            )\n            self.code_contents = updated_code\n            self.code_panel.delete(\"1.0\", \"end\")\n            self.code_panel.insert(\"1.0\", updated_code)\n            self._append_chat(\"System\", \"Code updated successfully!\")\n        except Exception as e:\n            self._append_chat(\"System\", f\"Edit failed: {e}\")\n\n    def _get_insertion_instructions(self, new_code: str) -> dict | None:\n        \"\"\"\n        Ask helper model for insertion point and lines to delete using line numbers,\n        with up to 3 verification attempts.\n        \"\"\"\n        numbered_code = self._add_line_numbers(self.code_contents)\n        system_prompt = (\n            \"You are a code editing assistant. Your job is to determine where to insert new code \"\n            \"and which lines (if any) to delete from the existing code.\\n\\n\"\n        )\n\n        user_prompt = (\n            \"You will receive:\\n\"\n            \"1. The current code with line numbers (format: '1 | code here')\\n\"\n            \"2. New code to insert\\n\\n\"\n            \"You must respond ONLY with JSON in this exact format:\\n\"\n            \"{\\n\"\n            '  \\\"insertion_point\\\": <line_number>,\\n'\n            '  \\\"delete_lines\\\": [<line_numbers>],\\n'\n            '  \\\"indent_spaces\\\": <number_of_spaces>\\n'\n            \"}\\n\\n\"\n            \"Rules:\\n\"\n            \"- insertion_point: The line number AFTER which to insert the new code (use 0 to insert at the beginning)\\n\"\n            \"- delete_lines: Array of line numbers to delete (can be empty [] if just inserting)\\n\"\n            \"- IMPORTANT: Do NOT try to match or adjust indentation.\\n\"\n            \"- IMPORTANT: Assume NEW CODE TO INSERT already has the correct indentation exactly as it should appear in the file.\\n\"\n            \"- Therefore, indent_spaces MUST be 0 in normal operation.\\n\"\n            \"- Only set indent_spaces to a nonzero value if the user explicitly requests automatic indentation.\\n\"\n            \"- Use the CURRENT line numbers you see - don't worry about how insertion affects numbering.\\n\"\n            \"- If replacing code, include those line numbers in delete_lines.\\n\"\n            \"- If just inserting, leave delete_lines empty.\\n\\n\"\n            \"Example 1 - Replace lines 5-7 (no auto-indentation):\\n\"\n            \"{\\\"insertion_point\\\": 4, \\\"delete_lines\\\": [5, 6, 7], \\\"indent_spaces\\\": 0}\\n\\n\"\n            \"Example 2 - Insert after line 10 (no auto-indentation):\\n\"\n            \"{\\\"insertion_point\\\": 10, \\\"delete_lines\\\": [], \\\"indent_spaces\\\": 0}\\n\\n\"\n            \"Example 3 - Insert at beginning (no auto-indentation):\\n\"\n            \"{\\\"insertion_point\\\": 0, \\\"delete_lines\\\": [], \\\"indent_spaces\\\": 0}\\n\\n\"\n            \"Respond with ONLY the JSON, no explanations.\\n\"\n            \"LAST ASSISTANT MESSAGE:\\n\"\n            f\"{self.conversation[-1]['content']}\\n\"\n            \"OLD CODE (with line numbers):\\n\"\n            f\"{numbered_code}\\n\\n\"\n            \"NEW CODE TO INSERT:\\n\"\n            f\"{new_code}\\n\"\n        )\n\n        model = self.helper_model.get()\n        client = self._get_client_for_model(model)\n        max_tokens = self._get_max_tokens_for_model(model)\n\n        conversation = [\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ]\n\n        # Initial attempt\n        data = self._call_helper_and_parse(client, model, max_tokens, conversation)\n        if not data:\n            return None\n\n        # Up to 3 verification loops\n        for attempt in range(3):\n            try:\n                updated_code = self._apply_line_based_edit(\n                    data[\"insertion_point\"],\n                    data[\"delete_lines\"],\n                    new_code,\n                    data[\"indent_spaces\"]\n                )\n                context_snippet = self._get_modification_context(\n                    updated_code,\n                    data[\"insertion_point\"],\n                    data[\"delete_lines\"],\n                    new_code,\n                    data[\"indent_spaces\"]\n                )\n                verification_prompt = (\n                    \"Here is the RESULT of your edit (showing only the modified section with 3 lines before and after):\\n\\n\"\n                    f\"{context_snippet}\\n\\n\"\n                    \"Check carefully:\\n\"\n                    \"- Is the indentation correct?\\n\"\n                    \"- Is the new code in the right place?\\n\"\n                    \"- Are there any duplicate lines?\\n\"\n                    \"- Does it match the surrounding code style?\\n\\n\"\n                    \"If everything looks CORRECT, respond with just: CORRECT\\n\"\n                    \"If something is WRONG, provide corrected JSON with the right insertion_point, delete_lines, and indent_spaces.\\n\"\n                    \"The JSON values you provide should refer to line numbers in the ORIGINAL, OLD CODE.\"\n                )\n                conversation.append({\"role\": \"assistant\", \"content\": json.dumps(data)})\n                conversation.append({\"role\": \"user\", \"content\": verification_prompt})\n\n                params = {\n                    \"model\": model,\n                    \"messages\": conversation,\n                    \"temperature\": self.helper_temp.get(),\n                }\n\n                if self._uses_max_completion_tokens(model):\n                    params[\"max_completion_tokens\"] = max_tokens\n                else:\n                    params[\"max_tokens\"] = max_tokens\n\n                verification_response = client.chat.completions.create(**params)\n                verification_text = verification_response.choices[0].message.content or \"\"\n\n                if \"CORRECT\" in verification_text.upper():\n                    return data\n\n                corrected_data = self._extract_json_from_text(verification_text)\n                if corrected_data and self._validate_json_format(corrected_data):\n                    data = corrected_data\n                else:\n                    # No valid correction, stop early\n                    break\n\n            except Exception:\n                # On error, stop verifying\n                break\n\n        return data\n\n    def _get_modification_context(self, updated_code: str, insertion_point: int, \n                                   delete_lines: list, new_code: str, indent_spaces: int) -> str:\n        \"\"\"\n        Extract a snippet showing the modification with lines before and after context.\n        Returns numbered lines.\n        \"\"\"\n        lines = updated_code.split(\"\\n\")\n        \n        # Calculate where the new code actually is in the updated file\n        # We need to figure out the range of lines that were affected\n        \n        # Start by finding where we inserted\n        num_deleted = len(delete_lines)\n        num_inserted = len(new_code.split(\"\\n\"))\n        \n        # The insertion point in the original file\n        original_insertion = insertion_point\n        \n        # In the new file, after deleting lines before the insertion point\n        deleted_before = sum(1 for line_num in delete_lines if line_num <= insertion_point)\n        adjusted_insertion = insertion_point - deleted_before\n        \n        # The new code spans from adjusted_insertion to adjusted_insertion + num_inserted\n        start_of_new_code = adjusted_insertion\n        end_of_new_code = adjusted_insertion + num_inserted\n        \n        # Get lines before and after\n        context_start = max(0, start_of_new_code - num_inserted * 4)\n        context_end = min(len(lines), end_of_new_code + num_inserted * 4)\n        \n        # Extract the context\n        context_lines = []\n        if context_start > 0:\n            context_lines += \"... (earlier code)\"\n        context_lines += lines[context_start:context_end]\n        if context_end < len(lines):\n            context_lines += \"... (later code)\"\n        # Add line numbers (starting from context_start + 1)\n        numbered_context = []\n        for i, line in enumerate(context_lines):\n            line_num = context_start + i + 1\n            numbered_context.append(f\"{line_num} | {line}\")\n        \n        return \"\\n\".join(numbered_context)\n\n    def _call_helper_and_parse(self, client, model: str, max_tokens: int, conversation: list) -> dict | None:\n        \"\"\"Call the helper model and parse JSON response.\"\"\"\n        params = {\n            \"model\": model,\n            \"messages\": conversation,\n            \"temperature\": self.helper_temp.get(),\n        }\n        \n        if self._uses_max_completion_tokens(model):\n            params[\"max_completion_tokens\"] = max_tokens\n        else:\n            params[\"max_tokens\"] = max_tokens\n        \n        try:\n            response = client.chat.completions.create(**params)\n            response_text = response.choices[0].message.content or \"\"\n            \n            print(\"Helper response:\", response_text)\n            \n            return self._extract_json_from_text(response_text)\n            \n        except Exception as e:\n            print(f\"Error calling helper: {e}\")\n            return None\n    \n    def _extract_json_from_text(self, text: str) -> dict | None:\n        \"\"\"Extract and parse JSON from text that may contain markdown or other content.\"\"\"\n        # Try to find JSON in the text\n        json_match = re.search(r'\\{[^}]+\\}', text, re.DOTALL)\n        if json_match:\n            text = json_match.group(0)\n        \n        try:\n            data = json.loads(text)\n            if self._validate_json_format(data):\n                return data\n        except:\n            pass\n        \n        return None\n    \n    def _validate_json_format(self, data: dict) -> bool:\n        \"\"\"Validate that JSON has required fields with correct types.\"\"\"\n        if \"insertion_point\" not in data or \"delete_lines\" not in data or \"indent_spaces\" not in data:\n            return False\n        \n        if not isinstance(data[\"insertion_point\"], int):\n            return False\n        \n        if not isinstance(data[\"delete_lines\"], list):\n            return False\n        \n        if not isinstance(data[\"indent_spaces\"], int):\n            return False\n        \n        return True\n\n    def _apply_line_based_edit(self, insertion_point: int, delete_lines: list, new_code: str, indent_spaces: int) -> str:\n        \"\"\"Apply insertion and deletion based on line numbers, with indentation.\"\"\"\n        lines = self.code_contents.split(\"\\n\")\n        \n        # Validate line numbers\n        if insertion_point < 0 or insertion_point > len(lines):\n            raise ValueError(f\"Invalid insertion point: {insertion_point}\")\n        \n        for line_num in delete_lines:\n            if line_num < 1 or line_num > len(lines):\n                raise ValueError(f\"Invalid line number to delete: {line_num}\")\n        \n        # Convert delete_lines to 0-indexed and sort in reverse order\n        delete_indices = sorted([line_num - 1 for line_num in delete_lines], reverse=True)\n        \n        # Adjust insertion point if we're deleting lines before it\n        adjusted_insertion = insertion_point\n        for idx in delete_indices:\n            if idx < insertion_point:\n                adjusted_insertion -= 1\n        \n        # Delete lines (in reverse order to preserve indices)\n        for idx in delete_indices:\n            del lines[idx]\n        \n        # Apply indentation to new code\n        indent = \" \" * indent_spaces\n        new_lines = new_code.split(\"\\n\")\n        indented_lines = [indent + line for line in new_lines]\n        \n        # Insert new code at the adjusted position\n        lines[adjusted_insertion:adjusted_insertion] = indented_lines\n        \n        return \"\\n\".join(lines)\n\n    def _replace_code_panel(self, code: str):\n        self.code_contents = code\n        self.code_panel.delete(\"1.0\", \"end\")\n        self.code_panel.insert(\"1.0\", code)\n\n    # -----------------------------\n    # Persistence\n    # -----------------------------\n    def save_conversation(self, path: str | None = None):\n        if path is None:\n            path = filedialog.asksaveasfilename(\n                defaultextension=\".json\",\n                filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")]\n            )\n            if not path:\n                return\n        try:\n            with open(path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(self.conversation, f, indent=2, ensure_ascii=False)\n            self.auto_save_path = path\n            messagebox.showinfo(\"Saved\", f\"Conversation saved to\\n{path}\")\n        except Exception as e:\n            messagebox.showerror(\"Save error\", str(e))\n\n    def load_conversation(self):\n        path = filedialog.askopenfilename(\n            defaultextension=\".json\",\n            filetypes=[(\"JSON files\", \"*.json\"), (\"All files\", \"*.*\")]\n        )\n        if not path:\n            return\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                raw = f.read().strip()\n            if not raw:\n                raise ValueError(\"File is empty.\")\n            loaded = json.loads(raw)\n        except json.JSONDecodeError as e:\n            messagebox.showerror(\"Load error\", f\"Invalid JSON:\\n{e}\")\n            return\n        except Exception as e:\n            messagebox.showerror(\"Load error\", str(e))\n            return\n    \n        if not isinstance(loaded, list):\n            messagebox.showerror(\n                \"Load error\",\n                f\"File must contain a list of messages, got {type(loaded).__name__}.\"\n            )\n            return\n    \n        self.conversation = loaded\n        self.auto_save_path = path\n        self._redraw_chat()\n        messagebox.showinfo(\"Loaded\", f\"Conversation loaded from\\n{path}\")\n    \n    def _redraw_chat(self):\n        for w in self.chat_inner_frame.winfo_children():\n            w.destroy()\n        self.current_message_label = None\n        for msg in self.conversation:\n            role = msg.get(\"role\")\n            content = msg.get(\"content\", \"\")\n            if role == \"system\":\n                continue\n            sender = \"You\" if role == \"user\" else \"Assistant\"\n            if role == \"assistant\":\n                self._replace_with_parsed_message(content)\n            else:\n                self._append_chat(sender, content)\n\n    # -----------------------------\n    # UI Helpers\n    # -----------------------------\n\n    def _append_chat(self, sender: str, text: str):\n        \"\"\"Modified for tighter user message spacing.\"\"\"\n        container = ttk.Frame(self.chat_inner_frame)\n        container.pack(fill=\"x\", padx=10, pady=5)\n\n        header = tk.Text(container, height=1, font=(\"TkDefaultFont\", 10, \"bold\"),\n                        relief=\"flat\", background=self.bg_color, highlightthickness=0)\n        header.insert(\"1.0\", f\"{sender}:\")\n        header.configure(state=\"disabled\")\n        header.pack(fill=\"x\")\n\n        # Dynamic height for content\n        line_count = text.count(\"\\n\") + 2\n        body = tk.Text(container, height=line_count, wrap=\"word\", relief=\"flat\",\n                      background=self.bg_color, highlightthickness=0)\n        body.insert(\"1.0\", text)\n        body.configure(state=\"disabled\")\n        body.pack(fill=\"x\", padx=5)\n        \n        if sender == \"Assistant\":\n            self.current_message_label = body\n            self.current_message_container = container\n\n        self.chat_canvas.update_idletasks()\n        self.chat_canvas.yview_moveto(1.0)\n\n    def _append_to_last_chat(self, text: str):\n        \"\"\"Append text and grow the text widget height dynamically.\"\"\"\n        if self.current_message_label:\n            self.current_message_label.configure(state=\"normal\")\n            self.current_message_label.insert(\"end\", text)\n            \n            line_count = int(self.current_message_label.index(\"end-1c\").split(\".\")[0])\n            self.current_message_label.configure(height=line_count, state=\"disabled\")\n            \n            self.chat_canvas.update_idletasks()\n            self.chat_canvas.yview_moveto(1.0)\n\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    ChatUI(root)\n    root.mainloop()\n```\n Here are my rules: **Never use ellipses or any placeholder text—inside or outside comments—to indicate omitted code; always supply the complete, runnable snippet.** Avoid rewriting entire files unless specifically asked."
  },
  {
    "role": "assistant",
    "content": "One potential change to your UI's code is to enhance the `CodeProposal` class to include a feature for users to edit the proposed code directly within the chat interface. This can be achieved by replacing the `Text` widget with a `CodeProposal` widget that includes a `Button` for editing.\n\nHere's an example of how you can implement this change:\n\n```python\nclass CodeProposal(ttk.Frame):\n    def __init__(self, parent, code: str, on_replace, on_add):\n        super().__init__(parent)\n        self.code = code\n\n        # Create a Text widget to display the code\n        self.text = tk.Text(\n            self,\n            height=code.count(\"\\n\") + 1,\n            wrap=\"none\",\n            font=(\"Courier New\", 10),\n            padx=5,\n            pady=5,\n            highlightthickness=1 # Border for code blocks\n        )\n        self.text.insert(\"1.0\", code)\n        self.text.configure(state=\"disabled\")\n        self.text.pack(fill=\"x\", padx=5, pady=(5, 2))\n\n        button_row = ttk.Frame(self)\n        button_row.pack(anchor=\"e\", padx=5, pady=(0, 5))\n\n        ttk.Button(button_row, text=\"Replace\", command=lambda: on_replace(code)).pack(side=\"right\", padx=2)\n        ttk.Button(button_row, text=\"Add\", command=lambda: on_add(code)).pack(side=\"right\", padx=2)\n        ttk.Button(button_row, text=\"Edit\", command=self.edit_code).pack(side=\"right\", padx=2)\n\n    def edit_code(self):\n        # Create a new window for editing the code\n        edit_window = tk.Toplevel(self)\n        edit_window.title(\"Edit Code\")\n\n        # Create a Text widget for editing the code\n        edit_text = tk.Text(edit_window)\n        edit_text.pack(fill=\"both\", expand=True)\n        edit_text.insert(\"1.0\", self.code)\n\n        # Create a Button to save the edited code\n        def save_code():\n            self.code = edit_text.get(\"1.0\", \"end-1c\")\n            self.text.configure(state=\"normal\")\n            self.text.delete(\"1.0\", \"end\")\n            self.text.insert(\"1.0\", self.code)\n            self.text.configure(state=\"disabled\")\n            edit_window.destroy()\n\n        ttk.Button(edit_window, text=\"Save\", command=save_code).pack()\n```\n\nThis change allows users to edit the proposed code directly within the chat interface, which can improve the overall user experience."
  }
]